{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2630,
     "status": "ok",
     "timestamp": 1652611858676,
     "user": {
      "displayName": "alessio giorlandino",
      "userId": "14669683435891599642"
     },
     "user_tz": -120
    },
    "id": "BGNG42Iq3mZ-",
    "outputId": "5564318e-51ac-47f0-9dd3-7d5003ff5ccd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyDOE in /usr/local/lib/python3.7/dist-packages (0.3.8)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pyDOE) (1.4.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pyDOE) (1.21.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyDOE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1652611858676,
     "user": {
      "displayName": "alessio giorlandino",
      "userId": "14669683435891599642"
     },
     "user_tz": -120
    },
    "id": "qPPr5oba3j88",
    "outputId": "658042e9-dd78-4208-8c86-44df6f833480"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.8.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import datetime, os\n",
    "#hide tf logs \n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # or any {'0', '1', '2'} \n",
    "#0 (default) shows all, 1 to filter out INFO logs, 2 to additionally filter out WARNING logs, and 3 to additionally filter out ERROR logs\n",
    "import scipy.optimize\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import time\n",
    "from pyDOE import lhs         #Latin Hypercube Sampling\n",
    "import seaborn as sns \n",
    "import codecs, json\n",
    "\n",
    "# generates same random numbers each time\n",
    "np.random.seed(1234)\n",
    "tf.random.set_seed(1234)\n",
    "\n",
    "print(\"TensorFlow version: {}\".format(tf.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "88G3Lt8xn-Oo"
   },
   "source": [
    "# *Data Prep*\n",
    "\n",
    "Training and Testing data is prepared from the solution file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1652611858677,
     "user": {
      "displayName": "alessio giorlandino",
      "userId": "14669683435891599642"
     },
     "user_tz": -120
    },
    "id": "HC_Gn7mu3j9B"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal\n",
    "#getting collocation points\n",
    "x = np.linspace(-1, 1, 128)                     # 256 points between -1 and 1 [256x1]\n",
    "y = np.linspace(-1, 1, 128)\n",
    "t = np.linspace(0, 0.2, 100)                    # 100 time points between 0 and 1 [100x1]\n",
    "X, Y, T = np.meshgrid(x, y ,t) \n",
    "usol=np.zeros((128, 128 ,100))\n",
    "pos = np.dstack((X[:,:,0], Y[:,:,0]))\n",
    "rv = multivariate_normal(mean=[0.0 , 0.0], cov=[0.05 , 0.05])\n",
    "usol[:][:,:,0] = rv.pdf(pos)\n",
    "\n",
    "#collocation points for every position and every time\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZyGxyaOAcqpi"
   },
   "source": [
    "# *Test Data*\n",
    "\n",
    "We prepare the test data to compare against the solution produced by the PINN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1652611858677,
     "user": {
      "displayName": "alessio giorlandino",
      "userId": "14669683435891599642"
     },
     "user_tz": -120
    },
    "id": "yddknKA2Xohp"
   },
   "outputs": [],
   "source": [
    "''' X_u_test = [X[i],T[i]] [25600,2] for interpolation'''\n",
    "X_u_test = np.hstack((X.flatten()[:,None], Y.flatten()[:,None], T.flatten()[:,None]))\n",
    "\n",
    "# Domain bounds\n",
    "lb = X_u_test[0]  # [-1. 0.]\n",
    "ub = X_u_test[-1] # [1.  0.99]\n",
    "\n",
    "'''\n",
    "   Fortran Style ('F') flatten,stacked column wise!\n",
    "   u = [c1 \n",
    "        c2\n",
    "        .\n",
    "        .\n",
    "        cn]\n",
    "\n",
    "   u =  [25600x1] \n",
    "'''\n",
    "u = usol.flatten('F')[:,None] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aJ5oBRtEXnyu"
   },
   "source": [
    "# *Training Data*\n",
    "\n",
    "The boundary conditions serve as the test data for the PINN and the collocation points are generated using **Latin Hypercube Sampling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1652611858677,
     "user": {
      "displayName": "alessio giorlandino",
      "userId": "14669683435891599642"
     },
     "user_tz": -120
    },
    "id": "8UVJmvZbXjXb"
   },
   "outputs": [],
   "source": [
    "def trainingdata(N_u,N_f):\n",
    "\n",
    "    '''Boundary Conditions'''\n",
    "\n",
    "    #Initial Condition -1 =< x =<1 and t = 0  \n",
    "    leftedge_x = np.hstack((X[0,:][:,None][:,:,0], X[0,:][:,None][:,:,0], T[0,:][:,None][:,:,0])) #L1\n",
    "    leftedge_u = usol[:,0][:,None]\n",
    "\n",
    "    #Boundary Condition x = -1 and 0 =< t =<1\n",
    "    bottomedge_x = np.hstack((X[:,0][:,None][0].T, X[0,:][:,None][0].T, T[:,0][:,None][0].T)) #L2\n",
    "    bottomedge_u = usol[-1,:][:,None]\n",
    "\n",
    "    #Boundary Condition x = 1 and 0 =< t =<1\n",
    "    topedge_x = np.hstack((X[:,-1][:,None][0].T, X[0,:][:,None][0].T, T[:,0][:,None][0].T)) #L3\n",
    "    topedge_u = usol[0,:][:,None]\n",
    "\n",
    "    all_X_u_train = np.vstack([leftedge_x, bottomedge_x, topedge_x]) # X_u_train [456,2] (456 = 256(L1)+100(L2)+100(L3))\n",
    "    all_u_train = np.vstack([leftedge_u, bottomedge_u, topedge_u])   #corresponding u [456x1]\n",
    "\n",
    "    #choose random N_u points for training\n",
    "    idx = np.random.choice(all_X_u_train.shape[0], N_u, replace=False) \n",
    "\n",
    "    X_u_train = all_X_u_train[idx, :] #choose indices from  set 'idx' (x,t)\n",
    "    u_train = all_u_train[idx,:]      #choose corresponding u\n",
    "\n",
    "    '''Collocation Points'''\n",
    "\n",
    "    # Latin Hypercube sampling for collocation points \n",
    "    # N_f sets of tuples(x,t)\n",
    "    X_f_train = lb + (ub-lb)*lhs(3,N_f) \n",
    "    X_f_train = np.vstack((X_f_train, X_u_train)) # append training points to collocation points \n",
    "\n",
    "    return X_f_train, X_u_train, u_train \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dp4nc2S7bwzz"
   },
   "source": [
    "# **PINN**\n",
    "\n",
    "Generate a **PINN** of L hidden layers, each with n neurons. \n",
    "\n",
    "Initialization: ***Xavier***\n",
    "\n",
    "Activation: *tanh (x)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 385,
     "status": "ok",
     "timestamp": 1652611859054,
     "user": {
      "displayName": "alessio giorlandino",
      "userId": "14669683435891599642"
     },
     "user_tz": -120
    },
    "id": "Ivj5SRpG3j9F"
   },
   "outputs": [],
   "source": [
    "class Sequentialmodel(tf.Module): \n",
    "    def __init__(self, layers, name=None):\n",
    "        self.itera = 0\n",
    "        self.W = []  #Weights and biases\n",
    "        self.parameters = 0 #total number of parameters\n",
    "        \n",
    "        for i in range(len(layers)-1):\n",
    "            \n",
    "            input_dim = layers[i]\n",
    "            output_dim = layers[i+1]\n",
    "            \n",
    "            #Xavier standard deviation \n",
    "            std_dv = np.sqrt((2.0/(input_dim + output_dim)))\n",
    "\n",
    "            #weights = normal distribution * Xavier standard deviation + 0\n",
    "            w = tf.random.normal([input_dim, output_dim], dtype = 'float64') * std_dv\n",
    "                       \n",
    "            w = tf.Variable(w, trainable=True, name = 'w' + str(i+1))\n",
    "\n",
    "            b = tf.Variable(tf.cast(tf.zeros([output_dim]), dtype = 'float64'), trainable = True, name = 'b' + str(i+1))\n",
    "                    \n",
    "            self.W.append(w)\n",
    "            self.W.append(b)\n",
    "            \n",
    "            self.parameters +=  input_dim * output_dim + output_dim\n",
    "    \n",
    "    def evaluate(self,x):\n",
    "        \n",
    "        x = (x-lb)/(ub-lb)\n",
    "        \n",
    "        a = x\n",
    "        \n",
    "        for i in range(len(layers)-2):\n",
    "            \n",
    "            z = tf.add(tf.matmul(a, self.W[2*i]), self.W[2*i+1])\n",
    "            a = tf.nn.tanh(z)\n",
    "            \n",
    "        a = tf.add(tf.matmul(a, self.W[-2]), self.W[-1]) # For regression, no activation to last layer\n",
    "        return a\n",
    "    \n",
    "    def get_weights(self):\n",
    "\n",
    "        parameters_1d = []  # [.... W_i,b_i.....  ] 1d array\n",
    "        \n",
    "        for i in range (len(layers)-1):\n",
    "            \n",
    "            w_1d = tf.reshape(self.W[2*i],[-1])   #flatten weights \n",
    "            b_1d = tf.reshape(self.W[2*i+1],[-1]) #flatten biases\n",
    "            \n",
    "            parameters_1d = tf.concat([parameters_1d, w_1d], 0) #concat weights \n",
    "            parameters_1d = tf.concat([parameters_1d, b_1d], 0) #concat biases\n",
    "        \n",
    "        return parameters_1d\n",
    "        \n",
    "    def set_weights(self,parameters):\n",
    "                \n",
    "        for i in range (len(layers)-1):\n",
    "\n",
    "            shape_w = tf.shape(self.W[2*i]).numpy() # shape of the weight tensor\n",
    "            size_w = tf.size(self.W[2*i]).numpy() #size of the weight tensor \n",
    "            \n",
    "            shape_b = tf.shape(self.W[2*i+1]).numpy() # shape of the bias tensor\n",
    "            size_b = tf.size(self.W[2*i+1]).numpy() #size of the bias tensor \n",
    "                        \n",
    "            pick_w = parameters[0:size_w] #pick the weights \n",
    "            self.W[2*i].assign(tf.reshape(pick_w,shape_w)) # assign  \n",
    "            parameters = np.delete(parameters,np.arange(size_w),0) #delete \n",
    "            \n",
    "            pick_b = parameters[0:size_b] #pick the biases \n",
    "            self.W[2*i+1].assign(tf.reshape(pick_b,shape_b)) # assign \n",
    "            parameters = np.delete(parameters,np.arange(size_b),0) #delete \n",
    "\n",
    "            \n",
    "    def loss_BC(self,x,y):\n",
    "\n",
    "        loss_u = tf.reduce_mean(tf.square(y-self.evaluate(x)))\n",
    "        return loss_u\n",
    "\n",
    "    def loss_PDE(self, x_to_train_f):\n",
    "    \n",
    "        g = tf.Variable(x_to_train_f, dtype = 'float64', trainable = False)\n",
    "    \n",
    "        cost=10 \n",
    "        sigma2=0.25\n",
    "\n",
    "        x_f = g[:,0:1]\n",
    "        y_f = g[:,1:2]\n",
    "        t_f = g[:,2:3]\n",
    "\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "\n",
    "            tape.watch(x_f)\n",
    "            tape.watch(y_f)\n",
    "            tape.watch(t_f)\n",
    "\n",
    "            g = tf.stack([x_f[:,0], y_f[:,0], t_f[:,0]], axis=1)   \n",
    "\n",
    "            z = self.evaluate(g)\n",
    "            p_x = tape.gradient(z,x_f)\n",
    "            p_y = tape.gradient(z,y_f)\n",
    "\n",
    "        p_t = tape.gradient(z,t_f)    \n",
    "        p_xx = tape.gradient(p_x, x_f)\n",
    "        p_yy = tape.gradient(p_y, y_f)\n",
    "        p_xy = tape.gradient(p_x, y_f)\n",
    "        p_yx = tape.gradient(p_y, x_f)\n",
    "\n",
    "        del tape\n",
    "\n",
    "        p=self.evaluate(g)\n",
    "\n",
    "        f = p_t - sigma2/2*p_xx - sigma2/2*p_yy\n",
    "\n",
    "        loss_f = tf.reduce_mean(tf.square(f))\n",
    "\n",
    "        return loss_f\n",
    "    \n",
    "    def loss(self,x,y,g):\n",
    "\n",
    "        loss_u = self.loss_BC(x,y)\n",
    "        loss_f = self.loss_PDE(g)\n",
    "\n",
    "        loss = loss_u + loss_f\n",
    "\n",
    "        return loss, loss_u, loss_f\n",
    "    \n",
    "    def optimizerfunc(self,parameters):\n",
    "        \n",
    "        self.set_weights(parameters)\n",
    "       \n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(self.trainable_variables)\n",
    "            \n",
    "            loss_val, loss_u, loss_f = self.loss(X_u_train, u_train, X_f_train)\n",
    "            \n",
    "        grads = tape.gradient(loss_val,self.trainable_variables)\n",
    "                \n",
    "        del tape\n",
    "        \n",
    "        grads_1d = [ ] #flatten grads \n",
    "        \n",
    "        for i in range (len(layers)-1):\n",
    "\n",
    "            grads_w_1d = tf.reshape(grads[2*i],[-1]) #flatten weights \n",
    "            grads_b_1d = tf.reshape(grads[2*i+1],[-1]) #flatten biases\n",
    "\n",
    "            grads_1d = tf.concat([grads_1d, grads_w_1d], 0) #concat grad_weights \n",
    "            grads_1d = tf.concat([grads_1d, grads_b_1d], 0) #concat grad_biases\n",
    "\n",
    "        return loss_val.numpy(), grads_1d.numpy()\n",
    "    \n",
    "    def optimizer_callback(self,parameters):\n",
    "               \n",
    "        loss_value, loss_u, loss_f = self.loss(X_u_train, u_train, X_f_train)\n",
    "        \n",
    "        u_pred = self.evaluate(X_u_test)\n",
    "        error_vec = np.linalg.norm((u-u_pred),2)/np.linalg.norm(u,2)\n",
    "        \n",
    "        tf.print(self.itera, loss_value, loss_u, loss_f, error_vec)\n",
    "        self.itera +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bOjuHdzAhib-"
   },
   "source": [
    "# *Solution Plot*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1652611859054,
     "user": {
      "displayName": "alessio giorlandino",
      "userId": "14669683435891599642"
     },
     "user_tz": -120
    },
    "id": "UWqNuRMLhg4m"
   },
   "outputs": [],
   "source": [
    "def solutionplot(u_pred,X_u_train,u_train):\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.axis('off')\n",
    "\n",
    "    gs0 = gridspec.GridSpec(2, 3)\n",
    "    gs0.update(top=1, bottom=0, left=0.1, right=2, wspace=0.3, hspace =0.4)\n",
    "    ax = plt.subplot(gs0[0, :])\n",
    "\n",
    "    h = ax.imshow(u_pred, interpolation='nearest', cmap='rainbow', \n",
    "                extent=[T.min(), T.max(), X.min(), X.max()], \n",
    "                origin='lower', aspect='auto')\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "    fig.colorbar(h, cax=cax)\n",
    "    \n",
    "    ax.plot(X_u_train[:,1], X_u_train[:,0], 'kx', label = 'Data (%d points)' % (u_train.shape[0]), markersize = 4, clip_on = False)\n",
    "\n",
    "    line = np.linspace(x.min(), x.max(), 2)[:,None]\n",
    "    #ax.plot(t[25]*np.ones((2,1)), line, 'w-', linewidth = 1)\n",
    "    #ax.plot(t[50]*np.ones((2,1)), line, 'w-', linewidth = 1)\n",
    "    #ax.plot(t[75]*np.ones((2,1)), line, 'w-', linewidth = 1)    \n",
    "\n",
    "    ax.set_xlabel('$t$')\n",
    "    ax.set_ylabel('$x$')\n",
    "    ax.legend(frameon=False, loc = 'best')\n",
    "    ax.set_title('$u(x,t)$', fontsize = 10)\n",
    "    \n",
    "    ''' \n",
    "    Slices of the solution at points t = 0.25, t = 0.50 and t = 0.75\n",
    "    '''\n",
    "    \n",
    "    ####### Row 1: u(t,x) slices ##################\n",
    "    #gs1 = gridspec.GridSpec(1, 3)\n",
    "    #gs1.update(top=0.3, bottom=-0.1, left=0.1, right=2, wspace=0.5)\n",
    "\n",
    "    ax = plt.subplot(gs0[1, 0])\n",
    "    #ax.plot(x,usol.T[0,:], 'b-', linewidth = 2, label = 'Exact')       \n",
    "    ax.plot(x,u_pred.T[0,:], 'r', linewidth = 2, label = 'Prediction')\n",
    "    ax.set_xlabel('$x$')\n",
    "    ax.set_ylabel('$u(x,t)$')    \n",
    "    ax.set_title('$t = 0.s$', fontsize = 10)\n",
    "    #ax.axis('square')\n",
    "    ax.set_xlim([-1.1,1.1])\n",
    "    ax.set_ylim([-0.1,9])\n",
    "\n",
    "    ax = plt.subplot(gs0[1, 1])\n",
    "    #ax.plot(x,usol.T[50,:], 'b-', linewidth = 2, label = 'Exact')       \n",
    "    ax.plot(x,u_pred.T[500,:], 'r', linewidth = 2, label = 'Prediction')\n",
    "    ax.set_xlabel('$x$')\n",
    "    ax.set_ylabel('$u(x,t)$')\n",
    "    #ax.axis('square')\n",
    "    ax.set_xlim([-1.1,1.1])\n",
    "    ax.set_ylim([-0.1,9])\n",
    "    ax.set_title('$t = 0.1s$', fontsize = 10)\n",
    "    ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.35), ncol=5, frameon=False)\n",
    "\n",
    "    ax = plt.subplot(gs0[1, 2])\n",
    "    #ax.plot(x,usol.T[75,:], 'b-', linewidth = 2, label = 'Exact')       \n",
    "    ax.plot(x,u_pred.T[750,:], 'r', linewidth = 2, label = 'Prediction')\n",
    "    ax.set_xlabel('$x$')\n",
    "    ax.set_ylabel('$u(x,t)$')\n",
    "    #ax.axis('square')\n",
    "    ax.set_xlim([-1.1,1.1])\n",
    "    ax.set_ylim([-0.1,9])    \n",
    "    ax.set_title('$t = 0.15s$', fontsize = 10)\n",
    "    \n",
    "    #plt.tight_layout()\n",
    "    plt.savefig('Ornstein-Uhlenbeck.png',dpi = 500)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YRuuEXx-eeWa"
   },
   "source": [
    "# *Model Training and Testing*\n",
    "\n",
    "A function '**model**' is defined to generate a NN as per the input set of hyperparameters, which is then trained and tested. The L2 Norm of the solution error is returned as a comparison metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WyH2oLRH3j9K",
    "outputId": "2a6e482f-0246-4bcc-f61a-b2eda8c48a7b",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.012534742170616977 0.00154855434373108 0.010986187826885896 1.311236329887067\n",
      "1 0.01116461388930518 0.0014454664014550043 0.0097191474878501761 1.3615971690664503\n",
      "2 0.0072524945445896164 0.0014699346480054251 0.0057825598965841911 1.487353409760186\n",
      "3 0.0041980671171782721 0.00083444192531202926 0.0033636251918662424 1.258846154290494\n",
      "4 0.0022082662136348415 0.00073613552871338911 0.0014721306849214523 1.1305504935985045\n",
      "5 0.0015050279695727419 0.000729846482230578 0.00077518148734216392 1.0683364559712631\n",
      "6 0.00099795248909520583 0.00056046761971835133 0.00043748486937685444 1.051995372761837\n",
      "7 0.00084272611218794938 0.00046596630706242215 0.00037675980512552723 1.0457505171739074\n",
      "8 0.000603806158407285 0.00025956433011024757 0.00034424182829703742 1.019426363909217\n",
      "9 0.00045637975515174948 0.00011596770610630592 0.00034041204904544355 1.0091042210898555\n",
      "10 0.00028368036188122135 3.1658038206609853e-05 0.00025202232367461149 1.0087642479938546\n",
      "11 0.00020664590685793159 1.94627400235813e-05 0.00018718316683435029 1.0083302379714505\n",
      "12 0.00015953036009403753 2.0817853770402565e-05 0.00013871250632363497 1.0067055632551036\n",
      "13 0.00012306498393779304 1.6286910671143864e-05 0.00010677807326664918 1.0035280366927046\n",
      "14 0.00010482717341939179 1.1591364044007922e-05 9.3235809375383878e-05 1.000923501366414\n",
      "15 9.5023692659935608e-05 6.9704342319588824e-06 8.8053258427976723e-05 1.0002187474041557\n",
      "16 8.6257942415665062e-05 4.7461261263664386e-06 8.1511816289298619e-05 0.9998786928982264\n",
      "17 6.600192992693024e-05 5.1289497323002805e-06 6.087298019462996e-05 0.9994710089556773\n",
      "18 4.4249987311450582e-05 7.5660321937167621e-06 3.6683955117733819e-05 0.9998100334636955\n",
      "19 2.7734522651726137e-05 6.759257201125653e-06 2.0975265450600484e-05 1.0011130889184394\n",
      "20 1.9163731989988235e-05 4.5029705747182993e-06 1.4660761415269934e-05 1.000381596066526\n",
      "21 1.8056247387110208e-05 4.4168774723338229e-06 1.3639369914776386e-05 1.0002483026528153\n",
      "22 1.7465094042317366e-05 4.0455098155474478e-06 1.3419584226769918e-05 1.0003886262156516\n",
      "23 1.6589186708932508e-05 3.5228560055876814e-06 1.3066330703344827e-05 1.0003917324717566\n",
      "24 1.5713630835323181e-05 3.098508360780548e-06 1.2615122474542632e-05 1.0002104922193984\n",
      "25 1.3277869805160235e-05 1.7577460156211603e-06 1.1520123789539074e-05 0.9999846464080585\n",
      "26 1.2512262616345569e-05 1.3029822197385888e-06 1.120928039660698e-05 0.9996574000967731\n",
      "27 1.1727297334035537e-05 1.0473770362594405e-06 1.0679920297776097e-05 0.9997366452375523\n",
      "28 1.0464218620167273e-05 1.0321864640114098e-06 9.4320321561558632e-06 0.9997304424899084\n",
      "29 8.153019710653216e-06 1.3433767866420355e-06 6.80964292401118e-06 1.0000653238755581\n",
      "30 6.2781199672387119e-06 1.9603092169309905e-06 4.3178107503077218e-06 1.0001934002814041\n",
      "31 5.6865261535239831e-06 1.8740412111675222e-06 3.8124849423564604e-06 1.000269629125292\n",
      "32 5.4515971426442495e-06 1.6236488689573656e-06 3.8279482736868839e-06 1.0001479490836211\n",
      "33 5.3366754830022279e-06 1.2630412889888105e-06 4.0736341940134174e-06 0.9999547562973433\n",
      "34 5.3199426149839807e-06 1.2130264947016068e-06 4.1069161202823741e-06 0.9999305162130386\n",
      "35 5.2915165400109915e-06 1.1587311607786966e-06 4.1327853792322946e-06 0.9999050604811731\n",
      "36 5.1404899835523815e-06 1.0833066972404292e-06 4.0571832863119525e-06 0.9998699358760361\n",
      "37 4.1958558086421235e-06 7.8169561220057278e-07 3.4141601964415505e-06 0.9996339026217245\n",
      "38 3.4620823070168692e-06 6.0586206151132977e-07 2.8562202455055393e-06 0.9994430886842293\n",
      "39 2.574281639195012e-06 3.4598037896271639e-07 2.2283012602322956e-06 0.9993981769920197\n",
      "40 2.1519510008027018e-06 2.3916415340685434e-07 1.9127868473958477e-06 0.9995189502635157\n",
      "41 2.1162362774355333e-06 2.3601610742538877e-07 1.8802201700101444e-06 0.9994184297712974\n",
      "42 2.0081256475953835e-06 2.0089999747141361e-07 1.8072256501239697e-06 0.9995486593893225\n",
      "43 1.9815623057125654e-06 1.8824512291397197e-07 1.7933171827985934e-06 0.9995362328094338\n",
      "44 1.9142479906161911e-06 1.6180037562032404e-07 1.7524476149958671e-06 0.9994867922195633\n",
      "45 1.8182907977862177e-06 1.5709399912185473e-07 1.661196798664363e-06 0.9994784399317002\n",
      "46 1.4458983900809402e-06 1.8989805747349895e-07 1.2560003326074413e-06 0.9994211868519918\n",
      "47 1.1859020918830643e-06 2.0958038907249475e-07 9.7632170281056948e-07 0.9995810201976121\n",
      "48 1.0353809045102387e-06 2.3637019026024615e-07 7.9901071424999267e-07 0.9994668026605031\n",
      "49 9.5011981883686656e-07 2.1061540740229838e-07 7.3950441143456823e-07 0.999524055959342\n",
      "50 9.2159769099072847e-07 1.9848642640139672e-07 7.2311126458933175e-07 0.9995855161849897\n",
      "51 9.1412325778494177e-07 1.9148419053184976e-07 7.22639067253092e-07 0.9995849805204887\n",
      "52 8.9611484121310833e-07 1.7421601804554895e-07 7.2189882316755941e-07 0.9995957245214316\n",
      "53 8.7950310210306224e-07 1.6546150711481644e-07 7.140415949882458e-07 0.9995939890866309\n",
      "54 8.7116627612997411e-07 1.6848095775711028e-07 7.0268531837286386e-07 0.9995891315545458\n",
      "55 8.6660689069717048e-07 1.7366463005319268e-07 6.9294226064397782e-07 0.9995888350981476\n",
      "56 8.6496619857073754e-07 1.7742487397343324e-07 6.875413245973043e-07 0.9995929766667447\n",
      "57 8.6399026025941966e-07 1.801787735172672e-07 6.8381148674215245e-07 0.9995943306882785\n",
      "58 8.610068876802549e-07 1.854228164948866e-07 6.7558407118536836e-07 0.999593148908915\n",
      "59 8.5351027818058475e-07 1.9477343994724483e-07 6.5873683823334e-07 0.9995898142092614\n",
      "60 8.4111795419762051e-07 2.0508775948000006e-07 6.3603019471762047e-07 0.9995817084569889\n",
      "61 8.1867449502140178e-07 2.1238723661993883e-07 6.06287258401463e-07 0.9995697544140272\n",
      "62 7.7489111373277915e-07 2.1240831020471586e-07 5.6248280352806331e-07 0.9995521921137723\n",
      "63 7.09403605980647e-07 1.9856787483198567e-07 5.1083573114866134e-07 0.9995401986350841\n",
      "64 6.2414439208560123e-07 1.7095592553839077e-07 4.5318846654721043e-07 0.9995468961543\n",
      "65 5.18477641927149e-07 1.3361858883371422e-07 3.8485905309343475e-07 0.9995718255481926\n",
      "66 4.4535663714796452e-07 9.1382509636750213e-08 3.5397412751121432e-07 0.9996390121682222\n",
      "67 4.291663111174312e-07 7.6611590908115808e-08 3.5255472020931538e-07 0.9996491876467312\n",
      "68 4.1418918427823638e-07 5.9821110837040545e-08 3.5436807344119587e-07 0.9996802634020453\n",
      "69 4.1239770342509407e-07 6.115193753955787e-08 3.5124576588553622e-07 0.9997105029290864\n",
      "70 4.09976167328832e-07 5.426549061046458e-08 3.5571067671836744e-07 0.9997105577774786\n",
      "71 4.0839271914668449e-07 5.1048536027322272e-08 3.5734418311936222e-07 0.9997034275211267\n",
      "72 4.0647520279544444e-07 4.7700053630291309e-08 3.5877514916515313e-07 0.9997010428718599\n",
      "73 4.0515550723434248e-07 4.6292066234875212e-08 3.5886344099946728e-07 0.9997033384729084\n",
      "74 4.0253207697452385e-07 4.3802364735355816e-08 3.5872971223916806e-07 0.9997071425491504\n",
      "75 3.9849671323739206e-07 4.0123558040871716e-08 3.5837315519652033e-07 0.99971016659178\n",
      "76 3.9305716668290257e-07 3.5420966799276057e-08 3.5763619988362651e-07 0.9997127825572192\n",
      "77 3.8558637906051859e-07 3.0574759177859667e-08 3.5501161988265894e-07 0.9997173465906156\n",
      "78 3.7323777811750974e-07 2.47692158316309e-08 3.4846856228587883e-07 0.9997244722482893\n",
      "79 3.4708963608219557e-07 1.7592823298448225e-08 3.2949681278374737e-07 0.9997268963210185\n",
      "80 3.0402174885694634e-07 6.57611443384331e-09 2.97445634423103e-07 0.9996930716992702\n",
      "81 2.691957969957632e-07 2.701144340003112e-08 2.4218435359573207e-07 0.9997604238810119\n",
      "82 2.4877974904946733e-07 1.1191259179904084e-08 2.3758848986956325e-07 0.9996636633272861\n",
      "83 2.0870207659796823e-07 1.1649672383000782e-08 1.9705240421496745e-07 0.999680755772993\n",
      "84 1.8540487994411457e-07 1.0814292719904964e-08 1.7459058722420961e-07 0.9996624443503164\n",
      "85 1.8494429105216377e-07 1.1141963012814457e-08 1.7380232803934932e-07 0.9996498183658274\n",
      "86 1.626631846376799e-07 1.2783635286697928e-08 1.4987954935098197e-07 0.9996197215357709\n",
      "87 1.5515404885293193e-07 1.1753881512594272e-08 1.4340016734033765e-07 0.9996254993494839\n",
      "88 1.4384697296295188e-07 1.1610501972410114e-08 1.3223647099054177e-07 0.9996388110197391\n",
      "89 1.3557337313344382e-07 1.0545637409288571e-08 1.2502773572415525e-07 0.9996460670588309\n",
      "90 1.2993527321164197e-07 1.0112243683124629e-08 1.1982302952851735e-07 0.9996509255700105\n",
      "91 1.2186148957268613e-07 1.1825673659478774e-08 1.1003581591320735e-07 0.9996559875560543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92 1.2015554010505809e-07 1.1504798516136288e-08 1.086507415889218e-07 0.999662209811048\n",
      "93 1.1877235053306029e-07 1.1819723142732143e-08 1.0695262739032815e-07 0.9996604629084314\n",
      "94 1.1426981712004643e-07 1.1418155205592413e-08 1.0285166191445402e-07 0.9996572812141635\n",
      "95 1.0753402521771911e-07 8.48126000708442e-09 9.9052765210634689e-08 0.9996431097162253\n",
      "96 1.0108775461478437e-07 3.6407039798212988e-09 9.7447050634963064e-08 0.9996150476234156\n",
      "97 9.6543909181779168e-08 2.445729093626133e-09 9.4098180088153039e-08 0.9996089987725748\n",
      "98 9.1930527656847524e-08 1.9188412753375455e-09 9.0011686381509977e-08 0.9996056945871877\n",
      "99 8.9747525937664759e-08 2.1611838612737916e-09 8.7586342076390974e-08 0.9995974048786318\n",
      "100 8.8200363400697342e-08 2.9314795750108309e-09 8.52688838256865e-08 0.9996126662863966\n",
      "101 8.6804094297795024e-08 3.0104623778151383e-09 8.3793631919979888e-08 0.9995955881482078\n",
      "102 8.6150551546633137e-08 2.6534262216461706e-09 8.3497125324986967e-08 0.9995909437250464\n",
      "103 8.5934472393131733e-08 2.6593465402807106e-09 8.3275125852851018e-08 0.9995895631177127\n",
      "104 8.5785572291092673e-08 2.5380391509201104e-09 8.3247533140172563e-08 0.9995894173238812\n",
      "105 8.5637582294454707e-08 2.3288033517840788e-09 8.3308778942670627e-08 0.9995891520801465\n",
      "106 8.5522449620766893e-08 2.176775965165897e-09 8.3345673655601e-08 0.9995889334266804\n",
      "107 8.5170830330674034e-08 2.1014782978927189e-09 8.306935203278132e-08 0.9995880024531032\n",
      "108 8.3287753657226749e-08 2.2907751659928389e-09 8.09969784912339e-08 0.9995830558206086\n",
      "109 8.0883433695636455e-08 2.8830922848716608e-09 7.8000341410764793e-08 0.9995773870571593\n",
      "110 7.5422383589954859e-08 3.687875235256004e-09 7.173450835469886e-08 0.9995673301270546\n",
      "111 6.77655119346715e-08 3.1632356207393554e-09 6.4602276313932149e-08 0.9995599797778643\n",
      "112 5.8127872151157716e-08 1.4087000776180255e-09 5.6719172073539693e-08 0.999558016079475\n",
      "113 5.5976125261529947e-08 1.4675881656452731e-09 5.4508537095884675e-08 0.9995670023515334\n",
      "114 5.5406085337954966e-08 1.2681271357297565e-09 5.413795820222521e-08 0.9995798021407645\n",
      "115 5.465998657326371e-08 9.4976906663093174e-10 5.3710217506632775e-08 0.9995713312698477\n",
      "116 5.4472850345783015e-08 1.0041975547969008e-09 5.3468652790986116e-08 0.9995724279793272\n",
      "117 5.4347936406831682e-08 1.0529178016797456e-09 5.3295018605151937e-08 0.9995733649425718\n",
      "118 5.4292273415456318e-08 1.0432257249463162e-09 5.324904769051e-08 0.9995745967477985\n",
      "119 5.4243869395995566e-08 1.0096321975433665e-09 5.32342371984522e-08 0.9995745154850846\n",
      "120 5.4161109313038809e-08 9.7289059074286018e-10 5.3188218722295947e-08 0.9995749293680813\n",
      "121 5.3750777314666871e-08 8.49278854243898e-10 5.2901498460422975e-08 0.9995749981673873\n",
      "122 5.3361773109549983e-08 8.3216200478330731e-10 5.2529611104766673e-08 0.9995755001461795\n",
      "123 5.2408253424562764e-08 8.656455965506966e-10 5.1542607828012066e-08 0.9995773412342712\n",
      "124 5.0835039693594941e-08 9.0932536051365477e-10 4.9925714333081288e-08 0.9995821320917466\n",
      "125 4.7746482805445758e-08 8.9308397501737173e-10 4.6853398830428386e-08 0.9995933527604332\n",
      "126 4.2993597124968874e-08 9.0828529484408049e-10 4.2085311830124792e-08 0.99960918138499\n",
      "127 3.7190594040627586e-08 1.3664113270863175e-09 3.5824182713541272e-08 0.9996249540193073\n",
      "128 3.2242709246386819e-08 1.0262437428460221e-09 3.12164655035408e-08 0.9996498852390341\n",
      "129 2.8760189330080373e-08 4.6461891635813825e-10 2.8295570413722234e-08 0.9996720239076282\n",
      "130 2.6941495716997722e-08 5.9950897181225376e-10 2.6341986745185468e-08 0.9996979418553242\n",
      "131 2.5837497796861619e-08 6.3317380674879029e-10 2.5204323990112829e-08 0.9996925313701361\n",
      "132 2.5609879110589995e-08 3.6381980529376921e-10 2.5246059305296226e-08 0.9997019923865895\n",
      "133 2.5091041191338485e-08 4.7709014046705808e-10 2.4613951050871428e-08 0.9997021701825554\n",
      "134 2.484922893413271e-08 6.6908818286589211e-10 2.4180140751266817e-08 0.9997049773914103\n",
      "135 2.4689605546483897e-08 7.5647418501366885e-10 2.3933131361470227e-08 0.9997075475724985\n",
      "136 2.4510396462381131e-08 8.5520986394620323e-10 2.3655186598434927e-08 0.999710009065872\n",
      "137 2.4429610950221074e-08 8.9086066513993624e-10 2.3538750285081137e-08 0.9997104418997433\n",
      "138 2.4389696815643148e-08 8.9694981394068655e-10 2.3492747001702463e-08 0.999709680094931\n",
      "139 2.43782527096369e-08 8.659808889059437e-10 2.3512271820730956e-08 0.999709610962037\n",
      "140 2.4372250615571435e-08 8.5510999977282824e-10 2.3517140615798607e-08 0.9997093692325184\n",
      "141 2.4367871647913463e-08 8.46962202012727e-10 2.3520909445900735e-08 0.9997094522767063\n",
      "142 2.4361195554319895e-08 8.413895482519436e-10 2.3519806006067951e-08 0.9997097463964111\n",
      "143 2.4345197616147834e-08 8.3867195786140673e-10 2.3506525658286426e-08 0.9997104373537319\n",
      "144 2.4307697127864915e-08 8.4169392972834484e-10 2.3466003198136571e-08 0.9997118301719036\n",
      "145 2.4221121406915443e-08 8.5824658389563054e-10 2.3362874823019813e-08 0.9997144216322696\n",
      "146 2.4009735311967693e-08 9.013811917818288e-10 2.3108354120185863e-08 0.9997194344886223\n",
      "147 2.3523056818592088e-08 9.8245651588054185e-10 2.2540600302711547e-08 0.9997287426547863\n",
      "148 2.2573110257944685e-08 1.0464711944842108e-09 2.1526639063460475e-08 0.9997443685995216\n",
      "149 2.1339304346386551e-08 1.0032663462807545e-09 2.0336038000105796e-08 0.9997663034825417\n",
      "150 2.044296584622751e-08 7.3314047732710687e-10 1.9709825368900404e-08 0.9997808148356234\n",
      "151 2.0200534587356456e-08 1.1396891312767188e-09 1.9060845456079737e-08 0.9998006609339708\n",
      "152 1.9595098390040973e-08 6.3789031500877e-10 1.8957208075032202e-08 0.9997897013013701\n",
      "153 1.9429365603158287e-08 5.7222248013443246e-10 1.8857143123023853e-08 0.9997815152008843\n",
      "154 1.9298807305223456e-08 5.4103413071361671e-10 1.8757773174509839e-08 0.9997738140458432\n",
      "155 1.9220883586640927e-08 6.0970474357235907e-10 1.8611178843068569e-08 0.9997700646003674\n",
      "156 1.9179522100979423e-08 6.6279964247135084e-10 1.8516722458508073e-08 0.9997721397770084\n",
      "157 1.9169183140329311e-08 6.6492573400900136e-10 1.8504257406320309e-08 0.9997722088699776\n",
      "158 1.9159908153646239e-08 6.4636971705719372e-10 1.8513538436589045e-08 0.9997709624404467\n",
      "159 1.9152609792682437e-08 6.3043398440121267e-10 1.8522175808281225e-08 0.9997700621019919\n",
      "160 1.9139328761605753e-08 6.0160027129142357e-10 1.8537728490314329e-08 0.999768055047195\n",
      "161 1.9123656771648897e-08 5.8065463521317481e-10 1.8543002136435723e-08 0.9997666436389142\n",
      "162 1.908451457151046e-08 5.4973967223281864e-10 1.8534774899277643e-08 0.9997644475329066\n",
      "163 1.90087683423008e-08 5.2152823858519336e-10 1.8487240103715607e-08 0.9997627411928394\n",
      "164 1.8821268402500362e-08 4.9950169906080032e-10 1.8321766703439563e-08 0.9997616713017167\n",
      "165 1.8402715045248382e-08 5.157736186427434e-10 1.788694142660564e-08 0.99976357465029\n",
      "166 1.7575417682373912e-08 6.512107947732153e-10 1.6924206887600696e-08 0.9997711779788254\n",
      "167 1.6642662117174932e-08 9.43999944614493e-10 1.5698662172560439e-08 0.9997819352627952\n",
      "168 1.5951407653939461e-08 8.44933819045506e-10 1.5106473834893954e-08 0.9997869128936089\n",
      "169 1.534512510530567e-08 8.6035836168798855e-10 1.4484766743617682e-08 0.9997916536920769\n",
      "170 1.5195453652015414e-08 7.6986145895596547e-10 1.4425592193059449e-08 0.9997952323935537\n",
      "171 1.5127827381734922e-08 8.0100585767878352e-10 1.4326821524056139e-08 0.9997986781660252\n",
      "172 1.5120892084751356e-08 7.9732712885019425e-10 1.4323564955901162e-08 0.9998012175078357\n",
      "173 1.5116958213433518e-08 8.0680840025519508e-10 1.4310149813178324e-08 0.999802267973554\n",
      "174 1.511559882043809e-08 8.0356046092965086e-10 1.4312038359508439e-08 0.9998018886095933\n",
      "175 1.5114391142065108e-08 8.0396055645689737e-10 1.4310430585608212e-08 0.9998020598225738\n",
      "176 1.5111088528356528e-08 8.0895771562079887e-10 1.4302130812735728e-08 0.9998030650376926\n",
      "177 1.5107866274618116e-08 8.1521501996871008e-10 1.4292651254649405e-08 0.9998040123793296\n",
      "178 1.5096528103505882e-08 8.3198260781596184e-10 1.4264545495689919e-08 0.9998061183362963\n",
      "179 1.5075124206660969e-08 8.6223004125275036e-10 1.4212894165408219e-08 0.9998092474792603\n",
      "180 1.5046094534680374e-08 8.97436549665888e-10 1.4148657985014487e-08 0.9998122169846404\n",
      "181 1.4998801341899377e-08 9.4677036818589554e-10 1.4052030973713483e-08 0.9998153239260231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182 1.4915955286434337e-08 1.01862650991755e-09 1.3897328776516787e-08 0.9998187994871417\n",
      "183 1.4755468661033795e-08 1.1390843493510709e-09 1.3616384311682724e-08 0.9998232220125136\n",
      "184 1.4467969733496523e-08 1.2959742263746304e-09 1.3171995507121893e-08 0.9998297101283509\n",
      "185 1.4372817913421482e-08 1.3597827048650151e-09 1.3013035208556467e-08 0.9998305097235403\n",
      "186 1.408085212039635e-08 1.3570724193143003e-09 1.2723779701082049e-08 0.9998317963436247\n",
      "187 1.3892288480130411e-08 1.2407836192334502e-09 1.2651504860896961e-08 0.9998284830746892\n",
      "188 1.3782445024745355e-08 1.1389636659310342e-09 1.2643481358814321e-08 0.9998231884086539\n",
      "189 1.3704768317893086e-08 1.0511771897369208e-09 1.2653591128156165e-08 0.99981715667\n",
      "190 1.3639877376958847e-08 9.9624834876409418e-10 1.2643629028194752e-08 0.9998120977218281\n",
      "191 1.3588898141243861e-08 9.9037341617028187e-10 1.259852472507358e-08 0.9998100449439395\n",
      "192 1.3571139052418782e-08 9.8454465661465175e-10 1.258659439580413e-08 0.9998085003756195\n",
      "193 1.3568202958410144e-08 9.67998721278257e-10 1.2600204237131887e-08 0.9998073197377195\n",
      "194 1.3566718091238243e-08 9.61306452201165e-10 1.2605411639037078e-08 0.9998073126411264\n",
      "195 1.3565087211047315e-08 9.5303806526909655e-10 1.2612049145778218e-08 0.9998070596994671\n",
      "196 1.3561092247967302e-08 9.4477607781333981e-10 1.2616316170153962e-08 0.9998070299823918\n",
      "197 1.355036125551915e-08 9.2823375590940525e-10 1.2622127499609744e-08 0.9998066200091962\n",
      "198 1.3526433164000068e-08 9.0782701591666294e-10 1.2618606148083406e-08 0.9998062749183824\n",
      "199 1.3462294727406154e-08 8.7025549541784671e-10 1.2592039231988307e-08 0.999805378029247\n",
      "200 1.331647325826288e-08 8.1971176736544565e-10 1.2496761490897434e-08 0.9998048921976894\n",
      "201 1.2926984453644453e-08 7.5241432598001115e-10 1.2174570127664442e-08 0.999806207809458\n",
      "202 1.2401673185264337e-08 7.2082587374317941e-10 1.1680847311521158e-08 0.9998101152393908\n",
      "203 1.1666653344633365e-08 6.7180062788500713e-10 1.0994852716748359e-08 0.9998073302081477\n",
      "204 1.1175782505844465e-08 6.599737268210528e-10 1.0515808779023413e-08 0.9998017361963778\n",
      "205 1.0452480409185464e-08 6.1634948529628092e-10 9.8361309238891828e-09 0.9997966521835333\n",
      "206 1.0257299750582789e-08 6.67165076453911e-10 9.5901346741288776e-09 0.9997962574037564\n",
      "207 1.0185640313886672e-08 6.804312607857728e-10 9.5052090531009e-09 0.9997956515695101\n",
      "208 1.0135127369344472e-08 6.61408649331717e-10 9.4737187200127555e-09 0.9997972971435328\n",
      "209 1.0108973782495308e-08 6.719399180709319e-10 9.437033864424376e-09 0.9998004169303523\n",
      "210 1.0073774833662146e-08 6.8547165851698083e-10 9.3883031751451649e-09 0.9998013823809321\n",
      "211 9.9893882238099264e-09 7.2697001474153675e-10 9.2624182090683891e-09 0.999803420611858\n",
      "212 9.9032733018528288e-09 7.6823743236998325e-10 9.1350358694828458e-09 0.9998049613082853\n",
      "213 9.7810213077668655e-09 8.1300998695902684e-10 8.9680113208078391e-09 0.9998071385208056\n",
      "214 9.7009825670043392e-09 8.3191745600122054e-10 8.86906511100312e-09 0.9998102700675872\n",
      "215 9.6588879744047849e-09 8.1797673455823172e-10 8.8409112398465534e-09 0.9998100338163596\n",
      "216 9.6034630613518061e-09 7.8465280075546068e-10 8.8188102605963451e-09 0.9998098291131641\n",
      "217 9.5185363371877045e-09 7.5708640125059835e-10 8.7614499359371059e-09 0.9998096458421983\n",
      "218 9.4483979915415761e-09 7.6196327456598447e-10 8.6864347169755912e-09 0.9998108234230934\n",
      "219 9.3663860411654124e-09 7.7797091722020394e-10 8.5884151239452083e-09 0.9998134774763712\n",
      "220 9.3411892267803444e-09 7.9835640589407174e-10 8.5428328208862729e-09 0.9998144491800558\n",
      "221 9.3039224104343824e-09 8.2418187230046435e-10 8.4797405381339184e-09 0.999817567484071\n",
      "222 9.2793178971342132e-09 8.4963485475788249e-10 8.42968304237633e-09 0.9998203355846326\n",
      "223 9.27043405698942e-09 8.4826341518838918e-10 8.42217064180103e-09 0.9998228071329214\n",
      "224 9.2643503581782217e-09 8.4961461973547553e-10 8.4147357384427455e-09 0.9998232318767482\n",
      "225 9.2617932100064311e-09 8.4478343722193436e-10 8.4170097727844972e-09 0.999823320585819\n",
      "226 9.2613223512724324e-09 8.4321103591550849e-10 8.4181113153569245e-09 0.9998232992171635\n",
      "227 9.2595436159547241e-09 8.4443429607521077e-10 8.4151093198795139e-09 0.9998235081825578\n",
      "228 9.25783326069974e-09 8.4752574482222166e-10 8.4103075158775177e-09 0.9998236766374865\n",
      "229 9.2554068875237587e-09 8.5345903835161281e-10 8.4019478491721465e-09 0.9998238575572481\n",
      "230 9.25372014406736e-09 8.5724505082508235e-10 8.3964750932422773e-09 0.9998238188110713\n",
      "231 9.2521784929826924e-09 8.5865272415736028e-10 8.3935257688253329e-09 0.9998235927007962\n",
      "232 9.2497776716741565e-09 8.5866239538422222e-10 8.391115276289934e-09 0.9998230870737843\n",
      "233 9.2466141913390876e-09 8.5672331388382326e-10 8.3898908774552645e-09 0.9998223858771459\n",
      "234 9.2413177158630661e-09 8.5224776926821122e-10 8.3890699465948546e-09 0.9998214259831836\n",
      "235 9.2314771906961554e-09 8.4384780885068806e-10 8.3876293818454665e-09 0.9998200692884953\n",
      "236 9.2086006806103008e-09 8.2876173078070288e-10 8.3798389498295979e-09 0.9998182354355374\n",
      "237 9.15025959222273e-09 8.02690144777217e-10 8.347569447445513e-09 0.9998155868955864\n",
      "238 8.9750623175219445e-09 7.5458722481917358e-10 8.2204750927027709e-09 0.9998116777360073\n",
      "239 8.6513813167934737e-09 7.0201191434080621e-10 7.9493694024526675e-09 0.9998046765659926\n",
      "240 8.3076602257468534e-09 7.2904706546492393e-10 7.578613160281929e-09 0.9998044480605645\n",
      "241 8.1820510750105757e-09 7.5004470486196475e-10 7.4320063701486113e-09 0.9997952779107594\n",
      "242 8.0740651974119629e-09 7.4768062372461844e-10 7.3263845736873441e-09 0.9997993610917622\n",
      "243 7.9997641270801063e-09 7.7915889512386912e-10 7.2206052319562367e-09 0.999806605036738\n",
      "244 7.9348738977639661e-09 7.493603509871503e-10 7.1855135467768165e-09 0.9998087464528134\n",
      "245 7.9029990381985185e-09 7.4305808661691617e-10 7.1599409515816027e-09 0.9998113911242885\n",
      "246 7.88798894305394e-09 7.409372610876595e-10 7.14705168196628e-09 0.9998117681016713\n",
      "247 7.8738714307626686e-09 7.5215866528488758e-10 7.12171276547778e-09 0.9998132225457046\n",
      "248 7.8672936036023347e-09 7.6444556371074976e-10 7.1028480398915853e-09 0.9998137413820497\n",
      "249 7.8624227648975223e-09 7.8509456596817375e-10 7.0773281989293485e-09 0.9998151248930425\n",
      "250 7.8606190306689928e-09 7.8856336345893492e-10 7.0720556672100584e-09 0.9998165914670851\n",
      "251 7.8577637760166467e-09 7.9363240557407362e-10 7.0641313704425728e-09 0.9998168355809023\n",
      "252 7.8556304852539181e-09 7.9533477110880607e-10 7.0602957141451119e-09 0.9998171227634325\n",
      "253 7.8516084025809729e-09 7.9729405935087615e-10 7.0543143432300966e-09 0.9998178125517094\n",
      "254 7.8447314608649939e-09 8.0004614094412628e-10 7.0446853199208684e-09 0.9998185993186427\n",
      "255 7.827782385738474e-09 8.060262082371519e-10 7.0217561775013218e-09 0.9998199136433376\n",
      "256 7.7893440928194668e-09 8.1700280361285115e-10 6.9723412892066148e-09 0.9998216407617039\n",
      "257 7.6968173748743962e-09 8.3198442269884156e-10 6.8648329521755539e-09 0.9998238701022977\n",
      "258 7.4877893568785515e-09 8.431490910463841e-10 6.644640265832167e-09 0.9998260744450038\n",
      "259 7.3723276494803362e-09 8.4029517668490745e-10 6.532032472795429e-09 0.9998258097750617\n",
      "260 6.8160458637587517e-09 8.4510911251364085e-10 5.970936751245111e-09 0.999825768445464\n",
      "261 6.478593795226679e-09 7.322792467219569e-10 5.7463145485047221e-09 0.9998221583166989\n",
      "262 6.116164082043996e-09 6.6803518304986448e-10 5.4481288989941318e-09 0.9998146772672947\n",
      "263 5.8725173098442251e-09 5.5048679654345018e-10 5.322030513300775e-09 0.9998116355992571\n",
      "264 5.806133282342845e-09 5.0656565455474379e-10 5.299567627788101e-09 0.9998093082780986\n",
      "265 5.7663933666371736e-09 5.1922300872282327e-10 5.24717035791435e-09 0.9998067844603241\n",
      "266 5.7395353634103418e-09 4.9547478635771757e-10 5.2440605770526242e-09 0.9998079000728017\n",
      "267 5.725399001119798e-09 4.814902026102554e-10 5.2439087985095425e-09 0.9998105388561468\n",
      "268 5.7131851224504386e-09 4.6954277696710712e-10 5.2436423454833315e-09 0.999809379588942\n",
      "269 5.7042222106099387e-09 4.580616648126242e-10 5.2461605457973147e-09 0.9998090549791899\n",
      "270 5.7000126541126168e-09 4.4943558131084181e-10 5.2505770728017747e-09 0.9998090935964833\n",
      "271 5.6945274775607049e-09 4.4027959525582996e-10 5.2542478823048753e-09 0.9998088973149127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "272 5.6872683228536754e-09 4.3116991963515646e-10 5.2560984032185192e-09 0.9998083744217312\n",
      "273 5.6777391423931106e-09 4.2430475415504468e-10 5.253434388238066e-09 0.9998073234909569\n",
      "274 5.667139272214153e-09 4.177563798362195e-10 5.2493828923779335e-09 0.9998063639865253\n",
      "275 5.6477568327653145e-09 4.1275792770172691e-10 5.2349989050635876e-09 0.999804756413742\n",
      "276 5.6081751195051058e-09 4.0328865551287816e-10 5.2048864639922277e-09 0.9998023412099937\n",
      "277 5.53661348067079e-09 3.9160846520394644e-10 5.1450050154668438e-09 0.9997995331748608\n",
      "278 5.4670956031399504e-09 3.6898687141126892e-10 5.0981087317286816e-09 0.9997968951491656\n",
      "279 5.2743695869009748e-09 3.244460915874646e-10 4.94992349531351e-09 0.999796937322253\n",
      "280 5.182438661724753e-09 2.9652364948821607e-10 4.8859150122365366e-09 0.9997986437743098\n",
      "281 5.0566778164565938e-09 2.910402058710219e-10 4.7656376105855715e-09 0.9997999628787464\n",
      "282 5.0180567689591613e-09 2.948956037731571e-10 4.7231611651860041e-09 0.9997964542392979\n",
      "283 4.9777326457000281e-09 2.8956092425600188e-10 4.6881717214440259e-09 0.9998005444705154\n",
      "284 4.95844486300796e-09 2.866837081224377e-10 4.6717611548855226e-09 0.9998004850221412\n",
      "285 4.9367023333902713e-09 2.8329143021013967e-10 4.6534109031801313e-09 0.9998005341957692\n",
      "286 4.91612206647696e-09 2.7783779384308947e-10 4.6382842726338705e-09 0.9998008108199732\n",
      "287 4.9005146770439649e-09 2.7105608731634164e-10 4.6294585897276231e-09 0.9998015433600614\n",
      "288 4.8934997559707353e-09 2.6913690174510284e-10 4.6243628542256327e-09 0.9998021646012519\n",
      "289 4.8884349090885884e-09 2.6458275167102186e-10 4.6238521574175665e-09 0.9998020545646376\n",
      "290 4.8848066407248436e-09 2.632212929403919e-10 4.6215853477844515e-09 0.9998019850304048\n",
      "291 4.8803089344588295e-09 2.5901614030174481e-10 4.6212927941570844e-09 0.99980159176259\n",
      "292 4.8742383935975412e-09 2.5508392317249113e-10 4.61915447042505e-09 0.9998015412986025\n",
      "293 4.8574113723710125e-09 2.4373016214043994e-10 4.6136812102305724e-09 0.9998010761163049\n",
      "294 4.8318718534894982e-09 2.317914643892035e-10 4.6000803891002947e-09 0.9998018678652417\n",
      "295 4.8038398618305214e-09 2.1990315518027611e-10 4.5839367066502455e-09 0.9998011913788017\n",
      "296 4.78486679816781e-09 2.1869997604806978e-10 4.56616682211974e-09 0.99980141285292\n",
      "297 4.7657687197422123e-09 2.2909378168788098e-10 4.5366749380543317e-09 0.9998016648996199\n",
      "298 4.7560757421010528e-09 2.2352174590580135e-10 4.5325539961952513e-09 0.9998017869778052\n",
      "299 4.7454287163410653e-09 2.1944377278491525e-10 4.52598494355615e-09 0.9998020150796504\n",
      "300 4.7291896236365137e-09 2.1760724923854407e-10 4.5115823743979694e-09 0.9998030154336804\n",
      "301 4.7202114963742993e-09 2.2057049962287623e-10 4.499640996751423e-09 0.9998037335116032\n",
      "302 4.7030360699819546e-09 2.2919107326249843e-10 4.4738449967194566e-09 0.9998050345823607\n",
      "303 4.68240114426478e-09 2.3247255493328856e-10 4.4499285893314915e-09 0.9998057158751438\n",
      "304 4.6446326411807359e-09 2.3152901346891005e-10 4.4131036277118255e-09 0.9998060873753575\n",
      "305 4.5929587903659145e-09 2.1243694642346627e-10 4.3805218439424483e-09 0.9998037080021711\n",
      "306 4.5415790296305641e-09 1.858649278471341e-10 4.35571410178343e-09 0.9998009643809472\n",
      "307 4.5051636021395991e-09 1.5633635483311452e-10 4.348827247306485e-09 0.999794926833078\n",
      "308 4.45092652847775e-09 1.54351660564339e-10 4.2965748679134106e-09 0.9997969133797564\n",
      "309 4.3643982954672866e-09 1.6666002200187012e-10 4.1977382734654165e-09 0.9997978398552317\n",
      "310 4.239033430699345e-09 1.7678836251330627e-10 4.0622450681860387e-09 0.999798870822573\n",
      "311 4.0882152143813471e-09 1.8613076028556656e-10 3.90208445409578e-09 0.9998022541205586\n",
      "312 3.87650925051324e-09 1.945217725892782e-10 3.6819874779239623e-09 0.9998103907129543\n",
      "313 3.6877300039128894e-09 2.0785836358952502e-10 3.4798716403233645e-09 0.9998154063176341\n",
      "314 3.5069998717141395e-09 1.7608706343044584e-10 3.3309128082836936e-09 0.9998218181148503\n",
      "315 3.2541879941492623e-09 1.9679468633098736e-10 3.0573933078182751e-09 0.9998303883693795\n",
      "316 3.1915243210633882e-09 2.0584105808617975e-10 2.9856832629772083e-09 0.9998320443493967\n",
      "317 3.1211782276957916e-09 2.1473188822400353e-10 2.906446339471788e-09 0.9998303951926967\n",
      "318 3.093613448872755e-09 2.082098837597606e-10 2.8854035651129946e-09 0.9998335866321604\n",
      "319 3.0561375730001215e-09 2.2604827262985365e-10 2.8300893003702678e-09 0.9998356487025363\n",
      "320 3.0266905823264034e-09 2.2857113031006448e-10 2.7981194520163389e-09 0.9998360679986985\n",
      "321 2.9973080975125555e-09 2.4253178881466047e-10 2.7547763086978951e-09 0.9998374898876854\n",
      "322 2.9846575802389566e-09 2.3424539331753832e-10 2.7504121869214185e-09 0.9998387309485199\n",
      "323 2.972391350453601e-09 2.3991412667549442e-10 2.7324772237781066e-09 0.999839606657531\n",
      "324 2.9629732044217717e-09 2.3803416112143288e-10 2.7249390433003387e-09 0.9998414961116686\n",
      "325 2.9569254062004117e-09 2.3821718864266664e-10 2.718708217557745e-09 0.9998434199839382\n",
      "326 2.9549211715337889e-09 2.3714522725218257e-10 2.7177759442816062e-09 0.9998442202593992\n",
      "327 2.9519982984778508e-09 2.39877134151137e-10 2.7121211643267139e-09 0.9998448458378557\n",
      "328 2.9475685618717023e-09 2.4144432746835392e-10 2.7061242344033485e-09 0.9998452189926238\n",
      "329 2.939340742854508e-09 2.4025754062034928e-10 2.6990832022341585e-09 0.999845685412562\n",
      "330 2.92955444412861e-09 2.3840442850682971e-10 2.69115001562178e-09 0.9998456993562986\n",
      "331 2.9161346800489613e-09 2.3951603875701509e-10 2.6766186412919465e-09 0.9998453296905855\n",
      "332 2.8978631531556671e-09 2.3172340701996986e-10 2.6661397461356971e-09 0.999845508108661\n",
      "333 2.855120662338347e-09 2.1768226190166269e-10 2.6374384004366842e-09 0.9998457327808993\n",
      "334 2.797401974731082e-09 1.992546852919924e-10 2.5981472894390895e-09 0.9998478688681972\n",
      "335 2.7768452407762245e-09 1.9000138882667644e-10 2.5868438519495482e-09 0.9998465587426514\n",
      "336 2.7286124168144921e-09 1.7217839525929972e-10 2.5564340215551924e-09 0.9998450540927148\n",
      "337 2.7092269278126093e-09 1.6782813021837723e-10 2.541398797594232e-09 0.9998422888050238\n",
      "338 2.6984500489479486e-09 1.665946288562206e-10 2.531855420091728e-09 0.9998425289596408\n",
      "339 2.6867804262556443e-09 1.665308719028836e-10 2.5202495543527606e-09 0.9998421589495396\n",
      "340 2.6786664515296157e-09 1.6440788765983136e-10 2.5142585638697843e-09 0.9998432221638195\n",
      "341 2.6697049964757626e-09 1.6601155036495158e-10 2.5036934461108109e-09 0.999844364503567\n",
      "342 2.6597832108763231e-09 1.6337954181862549e-10 2.4964036690576976e-09 0.9998455071476868\n",
      "343 2.6403667036083767e-09 1.6042219113960951e-10 2.4799445124687673e-09 0.9998471219877267\n",
      "344 2.6303949479230864e-09 1.5783647822230811e-10 2.4725584697007782e-09 0.9998483294903536\n",
      "345 2.607895466865485e-09 1.6625089203221842e-10 2.4416445748332665e-09 0.9998482978148698\n",
      "346 2.5925601181338823e-09 1.6739605259025771e-10 2.4251640655436245e-09 0.9998499113911917\n",
      "347 2.577670496986246e-09 1.6565907611865118e-10 2.4120114208675949e-09 0.9998520648127803\n",
      "348 2.5700009003751143e-09 1.6552424427501802e-10 2.4044766561000961e-09 0.9998528789471897\n",
      "349 2.5644454486480804e-09 1.6309365837058018e-10 2.4013517902775e-09 0.9998540031083861\n",
      "350 2.561125410601665e-09 1.6426220088309152e-10 2.3968632097185733e-09 0.9998542612417963\n",
      "351 2.5609093513433734e-09 1.6290121265805341e-10 2.39800813868532e-09 0.9998548804816891\n",
      "352 2.5602485643615111e-09 1.6338186905765609e-10 2.396866695303855e-09 0.9998548668844724\n",
      "353 2.5601346296349003e-09 1.6378676304914865e-10 2.3963478665857518e-09 0.999854720675999\n",
      "354 2.5600633975515137e-09 1.6374253389851858e-10 2.396320863652995e-09 0.9998547881775673\n",
      "355 2.5599504690633142e-09 1.6367069489376482e-10 2.3962797741695494e-09 0.999854933998806\n",
      "356 2.5598078815729697e-09 1.635164594302628e-10 2.3962914221427071e-09 0.9998550821793266\n",
      "357 2.5595206690456136e-09 1.6324563517092976e-10 2.3962750338746839e-09 0.9998553384069363\n",
      "358 2.5592443400998645e-09 1.6284075650410421e-10 2.3964035835957603e-09 0.9998555098984122\n",
      "359 2.559014269900661e-09 1.6258813645603174e-10 2.3964261334446291e-09 0.9998555908267047\n",
      "360 2.5588761905909522e-09 1.6234917934557795e-10 2.3965270112453741e-09 0.9998556144338613\n",
      "361 2.5586863951313606e-09 1.622203260132829e-10 2.3964660691180776e-09 0.9998555645089774\n",
      "362 2.5583479378707861e-09 1.6178830493307495e-10 2.3965596329377113e-09 0.9998555419393514\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363 2.5579557890296644e-09 1.6155850026918351e-10 2.3963972887604809e-09 0.9998553462191282\n",
      "364 2.5574057469119586e-09 1.6107481491070636e-10 2.3963309320012522e-09 0.9998551903947355\n",
      "365 2.5566780212939869e-09 1.6074232747539829e-10 2.3959356938185887e-09 0.9998548912996034\n",
      "366 2.555304606732659e-09 1.6006450070578077e-10 2.3952401060268782e-09 0.9998545349661957\n",
      "367 2.5527111271794343e-09 1.5898751717231981e-10 2.3937236100071146e-09 0.9998539714995263\n",
      "368 2.5473499985375669e-09 1.5692518700495457e-10 2.3904248115326125e-09 0.999853344185113\n",
      "369 2.5361109519232356e-09 1.5393028562345984e-10 2.3821806662997759e-09 0.9998525821708105\n",
      "370 2.5127234162140695e-09 1.4962573035116261e-10 2.3630976858629067e-09 0.9998523886209156\n",
      "371 2.4820255245110434e-09 1.5061083941294915e-10 2.3314146850980941e-09 0.9998511186866598\n",
      "372 2.4320175428797683e-09 1.4177282341823599e-10 2.2902447194615324e-09 0.9998542498934817\n",
      "373 2.3935978011783434e-09 1.650258547537325e-10 2.2285719464246107e-09 0.9998519702381239\n",
      "374 2.2860460184654778e-09 1.4335819096495203e-10 2.1426878275005259e-09 0.9998573917769055\n",
      "375 2.2438433742881902e-09 1.6018938674700813e-10 2.0836539875411822e-09 0.9998627592142855\n",
      "376 2.1121435808866714e-09 1.7041283703335046e-10 1.9417307438533209e-09 0.9998634726619366\n",
      "377 2.0251499572546e-09 1.9361359293716554e-10 1.8315363643174344e-09 0.999858014414381\n",
      "378 1.9905201259547007e-09 1.852707472219574e-10 1.8052493787327432e-09 0.9998586952295209\n",
      "379 1.9327841308853823e-09 1.8505403465741002e-10 1.7477300962279722e-09 0.9998558111002622\n",
      "380 1.9022410641005473e-09 1.9317104093190284e-10 1.7090700231686446e-09 0.9998558168003641\n",
      "381 1.871952455529048e-09 2.0154025068719662e-10 1.6704122048418512e-09 0.999858536872558\n",
      "382 1.8549954663903161e-09 2.0294825920206794e-10 1.6520472071882482e-09 0.9998603822298678\n",
      "383 1.8381893428126711e-09 1.9639948104931244e-10 1.6417898617633586e-09 0.9998602027394339\n",
      "384 1.8261153473529113e-09 1.9231910343493032e-10 1.633796243917981e-09 0.9998602576026169\n",
      "385 1.8216079413696364e-09 1.9080926871993662e-10 1.6307986726496997e-09 0.9998608233700043\n",
      "386 1.81836456768959e-09 1.9382218579141771e-10 1.6245423818981724e-09 0.9998613979240258\n",
      "387 1.8157169296147586e-09 1.9535652785744811e-10 1.6203604017573106e-09 0.9998622584978033\n",
      "388 1.8135153656536529e-09 1.9755487959585248e-10 1.6159604860578005e-09 0.9998628885167219\n",
      "389 1.8088880986449869e-09 2.0127040946155881e-10 1.6076176891834281e-09 0.999863683702616\n",
      "390 1.802664573080251e-09 2.0202495434811797e-10 1.6006396187321331e-09 0.9998643958703686\n",
      "391 1.7895241657311516e-09 2.0393106260969425e-10 1.5855931031214575e-09 0.9998647318155869\n",
      "392 1.7684479569432682e-09 2.02814203522731e-10 1.5656337534205373e-09 0.9998643554260327\n",
      "393 1.7433258844848803e-09 1.99005298260646e-10 1.5443205862242343e-09 0.9998629423277986\n",
      "394 1.7270141169355117e-09 2.0117582624731395e-10 1.5258382906881977e-09 0.9998618851527333\n",
      "395 1.7071834624540439e-09 1.9805313335242076e-10 1.5091303291016231e-09 0.9998596033975015\n",
      "396 1.6884919990871783e-09 1.9519456015165482e-10 1.4932974389355236e-09 0.9998575944792528\n",
      "397 1.6719209284548063e-09 1.9748651233677238e-10 1.474434416118034e-09 0.9998549231736811\n",
      "398 1.6414292079274361e-09 1.9900236685545788e-10 1.4424268410719782e-09 0.9998521148440053\n",
      "399 1.6111515574625549e-09 2.0400907915039461e-10 1.4071424783121603e-09 0.9998489441462307\n",
      "400 1.5911158358592317e-09 1.9967961309945281e-10 1.3914362227597789e-09 0.9998479048237326\n",
      "401 1.5851208383930691e-09 1.9990842860155835e-10 1.3852124097915108e-09 0.9998486218538066\n",
      "402 1.5821775667565075e-09 1.9992980430028646e-10 1.382247762456221e-09 0.9998470828916469\n",
      "403 1.5799539653348691e-09 1.9855246677754948e-10 1.3814014985573195e-09 0.9998469117446038\n",
      "404 1.5770358061797022e-09 1.9439461276735564e-10 1.3826411934123467e-09 0.9998465951142383\n",
      "405 1.5727632653008094e-09 1.9092621050542194e-10 1.3818370547953874e-09 0.9998465848233465\n",
      "406 1.5681000229199588e-09 1.8749431754948589e-10 1.3806057053704729e-09 0.9998467326584367\n",
      "407 1.5648183679078389e-09 1.8657562728250012e-10 1.3782427406253388e-09 0.9998469968932591\n",
      "408 1.5619538267490066e-09 1.869590372125629e-10 1.3749947895364437e-09 0.9998469552486327\n",
      "409 1.5600932562691815e-09 1.8736112680950493e-10 1.3727321294596766e-09 0.9998465702709441\n",
      "410 1.5592871525669325e-09 1.87632684041615e-10 1.3716544685253175e-09 0.9998463224434941\n",
      "411 1.5581082570161439e-09 1.8690168232716079e-10 1.371206574688983e-09 0.9998456458689622\n",
      "412 1.5571584427779704e-09 1.8655267062265022e-10 1.3706057721553203e-09 0.9998453446704035\n",
      "413 1.5558096470686923e-09 1.8553025178273591e-10 1.3702793952859564e-09 0.9998451329363381\n",
      "414 1.5550879542976268e-09 1.8449976529327538e-10 1.3705881890043514e-09 0.9998449084003059\n",
      "415 1.5527390193107213e-09 1.8401668965972989e-10 1.3687223296509915e-09 0.9998450147819268\n",
      "416 1.5466825627982715e-09 1.8404514909801156e-10 1.36263741370026e-09 0.9998457705650273\n",
      "417 1.5398510034912687e-09 1.8853844605894217e-10 1.3513125574323265e-09 0.9998456600480791\n",
      "418 1.5346622464486438e-09 1.9408235082999028e-10 1.3405798956186535e-09 0.999847419864862\n",
      "419 1.5205257301176961e-09 1.9412169047234976e-10 1.3264040396453464e-09 0.9998461386603802\n",
      "420 1.5125812274547171e-09 1.9999864854344314e-10 1.3125825789112739e-09 0.9998454476109094\n",
      "421 1.5094362776547321e-09 1.9615023059201819e-10 1.313286047062714e-09 0.9998465595593502\n",
      "422 1.5064191158919265e-09 1.9954782703992146e-10 1.3068712888520051e-09 0.9998476205644957\n",
      "423 1.502784221924943e-09 1.9949155518426916e-10 1.3032926667406737e-09 0.9998472396705435\n",
      "424 1.5014790476347523e-09 2.0110256694086922e-10 1.300376480693883e-09 0.9998473396531987\n",
      "425 1.4999090095597058e-09 2.0347959088417174e-10 1.2964294186755341e-09 0.9998476759234401\n",
      "426 1.4992081851082989e-09 2.055248400768264e-10 1.2936833450314725e-09 0.9998475863386591\n",
      "427 1.4986559099536498e-09 2.0531066434363144e-10 1.2933452456100183e-09 0.9998474865134815\n",
      "428 1.4982856731371637e-09 2.053147851257999e-10 1.2929708880113637e-09 0.9998471201333585\n",
      "429 1.4978923828391642e-09 2.0389767813378585e-10 1.2939947047053783e-09 0.9998466981548346\n",
      "430 1.4972179424503861e-09 2.0434797584607789e-10 1.2928699666043082e-09 0.9998464474399313\n",
      "431 1.4955089995187645e-09 2.0446150489901561e-10 1.2910474946197489e-09 0.999845832963889\n",
      "432 1.4943754435505143e-09 2.028483181839279e-10 1.2915271253665865e-09 0.9998456639020186\n",
      "433 1.4941499256776417e-09 2.0535471403393078e-10 1.288795211643711e-09 0.99984564906746\n",
      "434 1.4937346464090927e-09 2.0472065427030367e-10 1.2890139921387891e-09 0.9998456719207303\n",
      "435 1.4935860831508971e-09 2.0472141795163423e-10 1.2888646651992629e-09 0.999845564429913\n",
      "436 1.4934375646783287e-09 2.0534265101920628e-10 1.2880949136591224e-09 0.9998454531257203\n",
      "Training time: 311.87\n",
      "      fun: 1.4934375646783287e-09\n",
      " hess_inv: <3041x3041 LbfgsInvHessProduct with dtype=float64>\n",
      "      jac: array([ 2.09827914e-09, -3.43263898e-09,  3.23804732e-10, ...,\n",
      "        5.18759663e-09,  7.74351892e-09, -3.20861622e-08])\n",
      "  message: 'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "     nfev: 481\n",
      "      nit: 437\n",
      "     njev: 481\n",
      "   status: 0\n",
      "  success: True\n",
      "        x: array([-0.11516162, -0.06147434,  0.08135381, ..., -0.12999877,\n",
      "        0.01528935, -0.00041941])\n",
      "Test Error: 0.99985\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Solution Plot '"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_u = 300 #Total number of data points for 'u'\n",
    "N_f = 30000 #Total number of collocation points \n",
    "\n",
    "# Training data\n",
    "X_f_train, X_u_train, u_train = trainingdata(N_u, N_f)\n",
    "\n",
    "layers = np.array([3,20,20,20,20,20,20,20,20,1]) #8 hidden layers\n",
    "\n",
    "PINN = Sequentialmodel(layers)\n",
    "\n",
    "init_params = PINN.get_weights().numpy()\n",
    "\n",
    "start_time = time.time() \n",
    "\n",
    "# train the model with Scipy L-BFGS optimizer\n",
    "results = scipy.optimize.minimize(fun = PINN.optimizerfunc, \n",
    "                                  x0 = init_params, \n",
    "                                  args=(), \n",
    "                                  method='L-BFGS-B', \n",
    "                                  jac= True,        # If jac is True, fun is assumed to return the gradient along with the objective function\n",
    "                                  callback = PINN.optimizer_callback, \n",
    "                                  options = {'disp': None,\n",
    "                                            'maxcor': 200, \n",
    "                                            'ftol': 1 * np.finfo(float).eps,  #The iteration stops when (f^k - f^{k+1})/max{|f^k|,|f^{k+1}|,1} <= ftol\n",
    "                                            'gtol': 5e-8, \n",
    "                                            'maxfun':  50000, \n",
    "                                            'maxiter': 1000,\n",
    "                                            'iprint': -1,   #print update every 50 iterations\n",
    "                                            'maxls': 50})\n",
    "\n",
    "elapsed = time.time() - start_time                \n",
    "print('Training time: %.2f' % (elapsed))\n",
    "\n",
    "print(results)\n",
    "\n",
    "PINN.set_weights(results.x)\n",
    "\n",
    "''' Model Accuracy ''' \n",
    "u_pred = PINN.evaluate(X_u_test)\n",
    "\n",
    "error_vec = np.linalg.norm((u-u_pred),2)/np.linalg.norm(u,2)        # Relative L2 Norm of the error (Vector)\n",
    "print('Test Error: %.5f'  % (error_vec))\n",
    "\n",
    "#u_pred = np.reshape(u_pred,(256,1000),order='F')                        # Fortran Style ,stacked column wise!\n",
    "\n",
    "''' Solution Plot '''\n",
    "#solutionplot(u_pred,X_u_train,u_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_pred = np.reshape(u_pred,(128, 128, 100), order='F')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_3d_ic(time):\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    ax = plt.axes(projection='3d')\n",
    "    ax.plot_surface(X[:,:,0], Y[:,:,0], usol[:,:,time])\n",
    "\n",
    "def plot_3d_pred(time):\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    ax = plt.axes(projection='3d')\n",
    "    ax.plot_surface(X[:,:,0], Y[:,:,0], u_pred[:,:,time])\n",
    "    \n",
    "    \n",
    "def plot_2d(time):\n",
    "    plt.plot(x, u_pred_2[0][:,time])\n",
    "    #plt.ylim(0, 0.2)\n",
    "    #plt.xlim(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90f4741b3dee4ab692b44cc41d7414c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=48, description='time', max=99, step=2), Output()), _dom_classes=('widge…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fe4a4e158644afdaf8f7cd4259c6b80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=48, description='time', max=99, step=2), Output()), _dom_classes=('widge…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_3d_pred(time)>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ipywidgets\n",
    "\n",
    "        \n",
    "ipywidgets.interact(plot_3d_ic, time=(0, 99, 2))\n",
    "ipywidgets.interact(plot_3d_pred, time=(0, 99, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "OrnsteinUhlenbeck_lateral_ic.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
