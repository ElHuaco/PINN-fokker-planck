{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 2630,
     "status": "ok",
     "timestamp": 1652611858676,
     "user": {
      "displayName": "alessio giorlandino",
      "userId": "14669683435891599642"
     },
     "user_tz": -120
    },
    "id": "BGNG42Iq3mZ-",
    "outputId": "5564318e-51ac-47f0-9dd3-7d5003ff5ccd",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyDOE in /usr/local/lib/python3.7/dist-packages (0.3.8)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pyDOE) (1.4.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pyDOE) (1.21.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyDOE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1652611858676,
     "user": {
      "displayName": "alessio giorlandino",
      "userId": "14669683435891599642"
     },
     "user_tz": -120
    },
    "id": "qPPr5oba3j88",
    "outputId": "658042e9-dd78-4208-8c86-44df6f833480",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.8.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import datetime, os\n",
    "#hide tf logs \n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # or any {'0', '1', '2'} \n",
    "#0 (default) shows all, 1 to filter out INFO logs, 2 to additionally filter out WARNING logs, and 3 to additionally filter out ERROR logs\n",
    "import scipy.optimize\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import time\n",
    "from pyDOE import lhs         #Latin Hypercube Sampling\n",
    "import seaborn as sns \n",
    "import codecs, json\n",
    "\n",
    "# generates same random numbers each time\n",
    "np.random.seed(1234)\n",
    "tf.random.set_seed(1234)\n",
    "\n",
    "print(\"TensorFlow version: {}\".format(tf.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "88G3Lt8xn-Oo"
   },
   "source": [
    "# *Data Prep*\n",
    "\n",
    "Training and Testing data is prepared from the solution file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1652611858677,
     "user": {
      "displayName": "alessio giorlandino",
      "userId": "14669683435891599642"
     },
     "user_tz": -120
    },
    "id": "HC_Gn7mu3j9B",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal\n",
    "#getting collocation points\n",
    "x = np.linspace(-1, 1, 128)                     # 256 points between -1 and 1 [256x1]\n",
    "y = np.linspace(-1, 1, 128)\n",
    "t = np.linspace(0, 0.2, 100)                    # 100 time points between 0 and 1 [100x1]\n",
    "X, Y, T = np.meshgrid(x, y ,t) \n",
    "usol=np.zeros((128, 128 ,100))\n",
    "pos = np.dstack((X[:,:,0], Y[:,:,0]))\n",
    "rv = multivariate_normal(mean=[0.0 , 0.0], cov=[0.05 , 0.05])\n",
    "usol[:][:,:,0] = rv.pdf(pos)\n",
    "\n",
    "#collocation points for every position and every time\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZyGxyaOAcqpi"
   },
   "source": [
    "# *Test Data*\n",
    "\n",
    "We prepare the test data to compare against the solution produced by the PINN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1652611858677,
     "user": {
      "displayName": "alessio giorlandino",
      "userId": "14669683435891599642"
     },
     "user_tz": -120
    },
    "id": "yddknKA2Xohp",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "''' X_u_test = [X[i],T[i]] [25600,2] for interpolation'''\n",
    "X_u_test = np.hstack((X.flatten()[:,None], Y.flatten()[:,None], T.flatten()[:,None]))\n",
    "\n",
    "# Domain bounds\n",
    "lb = X_u_test[0]  # [-1. 0.]\n",
    "ub = X_u_test[-1] # [1.  0.99]\n",
    "\n",
    "'''\n",
    "   Fortran Style ('F') flatten,stacked column wise!\n",
    "   u = [c1 \n",
    "        c2\n",
    "        .\n",
    "        .\n",
    "        cn]\n",
    "\n",
    "   u =  [25600x1] \n",
    "'''\n",
    "u = usol.flatten('F')[:,None] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aJ5oBRtEXnyu"
   },
   "source": [
    "# *Training Data*\n",
    "\n",
    "The boundary conditions serve as the test data for the PINN and the collocation points are generated using **Latin Hypercube Sampling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainingdata(N_u,N_f):\n",
    "\n",
    "    '''Boundary Conditions'''\n",
    "\n",
    "    #Initial Condition -1 =< x,y =<1 and t = 0  \n",
    "    initial_xy = np.hstack((np.vstack(X[:,:,0][:,:,None]), np.vstack(Y[:,:,0][:,:,None]) ,np.vstack(T[:,:,0][:,:,None]))) #L1\n",
    "    initial_u = np.vstack(usol[:][:,:,0][:,:,None])\n",
    "\n",
    "    #Boundary Condition -1 < x < 1, y = -1 and 0 =< t =<1\n",
    "    bottomedge_xy = np.hstack((np.tile(X[0,:,0], 100)[:,None], np.tile(Y[0,:,0], 100)[:,None], np.hstack((np.tile(T[0,0,:][:,None], 128)))[:,None])) #L2\n",
    "    bottomedge_u = np.tile(usol[:,-1,-1], 100)[:,None]\n",
    "\n",
    "    #Boundary Condition -1 < x < 1, y = 1 and 0 =< t =<1\n",
    "    topedge_xy = np.hstack((np.tile(X[0,:,0], 100)[:,None], np.tile(Y[-1,:,0], 100)[:,None], np.hstack((np.tile(T[0,0,:][:,None], 128)))[:,None])) #L3\n",
    "    topedge_u = np.tile(usol[:,-1,-1], 100)[:,None]\n",
    "    \n",
    "    #Boundary Condition x = -1, -1 < y < 1 and 0 =< t =<1\n",
    "    leftedge_xy = np.hstack((np.tile(X[:,0,0], 100)[:,None], np.tile(Y[:,0,0], 100)[:,None], np.hstack((np.tile(T[0,0,:][:,None], 128)))[:,None])) #L4\n",
    "    leftedge_u = np.tile(usol[:,-1,-1], 100)[:,None]\n",
    "\n",
    "    #Boundary Condition x = 1, -1 < y < 1 and 0 =< t =<1\n",
    "    rightedge_x = np.hstack((np.tile(X[:,-1,0], 100)[:,None], np.tile(Y[:,0,0], 100)[:,None], np.hstack((np.tile(T[0,0,:][:,None], 128)))[:,None])) #L5\n",
    "    rightedge_u = np.tile(usol[:,-1,-1], 100)[:,None]\n",
    "\n",
    "    all_X_u_train = np.vstack([initial_xy, bottomedge_xy, topedge_xy, leftedge_xy, rightedge_x]) # X_u_train [456,2] (456 = 256(L1)+100(L2)+100(L3))\n",
    "    all_u_train = np.vstack([initial_u, bottomedge_u, topedge_u, leftedge_u, rightedge_u])   #corresponding u [456x1]\n",
    "\n",
    "    #choose random N_u points for training\n",
    "    idx = np.random.choice(all_X_u_train.shape[0], N_u, replace=False) \n",
    "\n",
    "    X_u_train = all_X_u_train[idx, :] #choose indices from  set 'idx' (x,t)\n",
    "    u_train = all_u_train[idx,:]      #choose corresponding u\n",
    "\n",
    "    '''Collocation Points'''\n",
    "\n",
    "    # Latin Hypercube sampling for collocation points \n",
    "    # N_f sets of tuples(x,t)\n",
    "    X_f_train = lb + (ub-lb)*lhs(3,N_f) \n",
    "    X_f_train = np.vstack((X_f_train, X_u_train)) # append training points to collocation points \n",
    "    return X_f_train, X_u_train, u_train \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dp4nc2S7bwzz"
   },
   "source": [
    "# **PINN**\n",
    "\n",
    "Generate a **PINN** of L hidden layers, each with n neurons. \n",
    "\n",
    "Initialization: ***Xavier***\n",
    "\n",
    "Activation: *tanh (x)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "executionInfo": {
     "elapsed": 385,
     "status": "ok",
     "timestamp": 1652611859054,
     "user": {
      "displayName": "alessio giorlandino",
      "userId": "14669683435891599642"
     },
     "user_tz": -120
    },
    "id": "Ivj5SRpG3j9F",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Sequentialmodel(tf.Module): \n",
    "    def __init__(self, layers, name=None):\n",
    "        self.itera = 0\n",
    "        self.W = []  #Weights and biases\n",
    "        self.parameters = 0 #total number of parameters\n",
    "        \n",
    "        for i in range(len(layers)-1):\n",
    "            \n",
    "            input_dim = layers[i]\n",
    "            output_dim = layers[i+1]\n",
    "            \n",
    "            #Xavier standard deviation \n",
    "            std_dv = np.sqrt((2.0/(input_dim + output_dim)))\n",
    "\n",
    "            #weights = normal distribution * Xavier standard deviation + 0\n",
    "            w = tf.random.normal([input_dim, output_dim], dtype = 'float64') * std_dv\n",
    "                       \n",
    "            w = tf.Variable(w, trainable=True, name = 'w' + str(i+1))\n",
    "\n",
    "            b = tf.Variable(tf.cast(tf.zeros([output_dim]), dtype = 'float64'), trainable = True, name = 'b' + str(i+1))\n",
    "                    \n",
    "            self.W.append(w)\n",
    "            self.W.append(b)\n",
    "            \n",
    "            self.parameters +=  input_dim * output_dim + output_dim\n",
    "    \n",
    "    def evaluate(self,x):\n",
    "        \n",
    "        x = (x-lb)/(ub-lb)\n",
    "        \n",
    "        a = x\n",
    "        \n",
    "        for i in range(len(layers)-2):\n",
    "            \n",
    "            z = tf.add(tf.matmul(a, self.W[2*i]), self.W[2*i+1])\n",
    "            a = tf.nn.tanh(z)\n",
    "            \n",
    "        a = tf.add(tf.matmul(a, self.W[-2]), self.W[-1]) # For regression, no activation to last layer\n",
    "        return a\n",
    "    \n",
    "    def get_weights(self):\n",
    "\n",
    "        parameters_1d = []  # [.... W_i,b_i.....  ] 1d array\n",
    "        \n",
    "        for i in range (len(layers)-1):\n",
    "            \n",
    "            w_1d = tf.reshape(self.W[2*i],[-1])   #flatten weights \n",
    "            b_1d = tf.reshape(self.W[2*i+1],[-1]) #flatten biases\n",
    "            \n",
    "            parameters_1d = tf.concat([parameters_1d, w_1d], 0) #concat weights \n",
    "            parameters_1d = tf.concat([parameters_1d, b_1d], 0) #concat biases\n",
    "        \n",
    "        return parameters_1d\n",
    "        \n",
    "    def set_weights(self,parameters):\n",
    "                \n",
    "        for i in range (len(layers)-1):\n",
    "\n",
    "            shape_w = tf.shape(self.W[2*i]).numpy() # shape of the weight tensor\n",
    "            size_w = tf.size(self.W[2*i]).numpy() #size of the weight tensor \n",
    "            \n",
    "            shape_b = tf.shape(self.W[2*i+1]).numpy() # shape of the bias tensor\n",
    "            size_b = tf.size(self.W[2*i+1]).numpy() #size of the bias tensor \n",
    "                        \n",
    "            pick_w = parameters[0:size_w] #pick the weights \n",
    "            self.W[2*i].assign(tf.reshape(pick_w,shape_w)) # assign  \n",
    "            parameters = np.delete(parameters,np.arange(size_w),0) #delete \n",
    "            \n",
    "            pick_b = parameters[0:size_b] #pick the biases \n",
    "            self.W[2*i+1].assign(tf.reshape(pick_b,shape_b)) # assign \n",
    "            parameters = np.delete(parameters,np.arange(size_b),0) #delete \n",
    "\n",
    "            \n",
    "    def loss_BC(self,x,y):\n",
    "\n",
    "        loss_u = tf.reduce_mean(tf.square(y-self.evaluate(x)))\n",
    "        return loss_u\n",
    "\n",
    "    def loss_PDE(self, x_to_train_f):\n",
    "    \n",
    "        g = tf.Variable(x_to_train_f, dtype = 'float64', trainable = False)\n",
    "    \n",
    "        cost=10 \n",
    "        sigma2=0.25\n",
    "\n",
    "        x_f = g[:,0:1]\n",
    "        y_f = g[:,1:2]\n",
    "        t_f = g[:,2:3]\n",
    "\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "\n",
    "            tape.watch(x_f)\n",
    "            tape.watch(y_f)\n",
    "            tape.watch(t_f)\n",
    "\n",
    "            g = tf.stack([x_f[:,0], y_f[:,0], t_f[:,0]], axis=1)   \n",
    "\n",
    "            z = self.evaluate(g)\n",
    "            p_x = tape.gradient(z,x_f)\n",
    "            p_y = tape.gradient(z,y_f)\n",
    "\n",
    "        p_t = tape.gradient(z,t_f)    \n",
    "        p_xx = tape.gradient(p_x, x_f)\n",
    "        p_yy = tape.gradient(p_y, y_f)\n",
    "        p_xy = tape.gradient(p_x, y_f)\n",
    "        p_yx = tape.gradient(p_y, x_f)\n",
    "\n",
    "        del tape\n",
    "\n",
    "        p=self.evaluate(g)\n",
    "\n",
    "        f = p_t - sigma2/2*p_xx - sigma2/2*p_yy\n",
    "\n",
    "        loss_f = tf.reduce_mean(tf.square(f))\n",
    "\n",
    "        return loss_f\n",
    "    \n",
    "    def loss(self,x,y,g):\n",
    "\n",
    "        loss_u = self.loss_BC(x,y)\n",
    "        loss_f = self.loss_PDE(g)\n",
    "\n",
    "        loss = loss_u + loss_f\n",
    "\n",
    "        return loss, loss_u, loss_f\n",
    "    \n",
    "    def optimizerfunc(self,parameters):\n",
    "        \n",
    "        self.set_weights(parameters)\n",
    "       \n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(self.trainable_variables)\n",
    "            \n",
    "            loss_val, loss_u, loss_f = self.loss(X_u_train, u_train, X_f_train)\n",
    "            \n",
    "        grads = tape.gradient(loss_val,self.trainable_variables)\n",
    "                \n",
    "        del tape\n",
    "        \n",
    "        grads_1d = [ ] #flatten grads \n",
    "        \n",
    "        for i in range (len(layers)-1):\n",
    "\n",
    "            grads_w_1d = tf.reshape(grads[2*i],[-1]) #flatten weights \n",
    "            grads_b_1d = tf.reshape(grads[2*i+1],[-1]) #flatten biases\n",
    "\n",
    "            grads_1d = tf.concat([grads_1d, grads_w_1d], 0) #concat grad_weights \n",
    "            grads_1d = tf.concat([grads_1d, grads_b_1d], 0) #concat grad_biases\n",
    "\n",
    "        return loss_val.numpy(), grads_1d.numpy()\n",
    "    \n",
    "    def optimizer_callback(self,parameters):\n",
    "               \n",
    "        loss_value, loss_u, loss_f = self.loss(X_u_train, u_train, X_f_train)\n",
    "        \n",
    "        u_pred = self.evaluate(X_u_test)\n",
    "        error_vec = np.linalg.norm((u-u_pred),2)/np.linalg.norm(u,2)\n",
    "        \n",
    "        tf.print(self.itera, loss_value, loss_u, loss_f, error_vec)\n",
    "        self.itera +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bOjuHdzAhib-"
   },
   "source": [
    "# *Solution Plot*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1652611859054,
     "user": {
      "displayName": "alessio giorlandino",
      "userId": "14669683435891599642"
     },
     "user_tz": -120
    },
    "id": "UWqNuRMLhg4m",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def solutionplot(u_pred,X_u_train,u_train):\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.axis('off')\n",
    "\n",
    "    gs0 = gridspec.GridSpec(2, 3)\n",
    "    gs0.update(top=1, bottom=0, left=0.1, right=2, wspace=0.3, hspace =0.4)\n",
    "    ax = plt.subplot(gs0[0, :])\n",
    "\n",
    "    h = ax.imshow(u_pred, interpolation='nearest', cmap='rainbow', \n",
    "                extent=[T.min(), T.max(), X.min(), X.max()], \n",
    "                origin='lower', aspect='auto')\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "    fig.colorbar(h, cax=cax)\n",
    "    \n",
    "    ax.plot(X_u_train[:,1], X_u_train[:,0], 'kx', label = 'Data (%d points)' % (u_train.shape[0]), markersize = 4, clip_on = False)\n",
    "\n",
    "    line = np.linspace(x.min(), x.max(), 2)[:,None]\n",
    "    #ax.plot(t[25]*np.ones((2,1)), line, 'w-', linewidth = 1)\n",
    "    #ax.plot(t[50]*np.ones((2,1)), line, 'w-', linewidth = 1)\n",
    "    #ax.plot(t[75]*np.ones((2,1)), line, 'w-', linewidth = 1)    \n",
    "\n",
    "    ax.set_xlabel('$t$')\n",
    "    ax.set_ylabel('$x$')\n",
    "    ax.legend(frameon=False, loc = 'best')\n",
    "    ax.set_title('$u(x,t)$', fontsize = 10)\n",
    "    \n",
    "    ''' \n",
    "    Slices of the solution at points t = 0.25, t = 0.50 and t = 0.75\n",
    "    '''\n",
    "    \n",
    "    ####### Row 1: u(t,x) slices ##################\n",
    "    #gs1 = gridspec.GridSpec(1, 3)\n",
    "    #gs1.update(top=0.3, bottom=-0.1, left=0.1, right=2, wspace=0.5)\n",
    "\n",
    "    ax = plt.subplot(gs0[1, 0])\n",
    "    #ax.plot(x,usol.T[0,:], 'b-', linewidth = 2, label = 'Exact')       \n",
    "    ax.plot(x,u_pred.T[0,:], 'r', linewidth = 2, label = 'Prediction')\n",
    "    ax.set_xlabel('$x$')\n",
    "    ax.set_ylabel('$u(x,t)$')    \n",
    "    ax.set_title('$t = 0.s$', fontsize = 10)\n",
    "    #ax.axis('square')\n",
    "    ax.set_xlim([-1.1,1.1])\n",
    "    ax.set_ylim([-0.1,9])\n",
    "\n",
    "    ax = plt.subplot(gs0[1, 1])\n",
    "    #ax.plot(x,usol.T[50,:], 'b-', linewidth = 2, label = 'Exact')       \n",
    "    ax.plot(x,u_pred.T[500,:], 'r', linewidth = 2, label = 'Prediction')\n",
    "    ax.set_xlabel('$x$')\n",
    "    ax.set_ylabel('$u(x,t)$')\n",
    "    #ax.axis('square')\n",
    "    ax.set_xlim([-1.1,1.1])\n",
    "    ax.set_ylim([-0.1,9])\n",
    "    ax.set_title('$t = 0.1s$', fontsize = 10)\n",
    "    ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.35), ncol=5, frameon=False)\n",
    "\n",
    "    ax = plt.subplot(gs0[1, 2])\n",
    "    #ax.plot(x,usol.T[75,:], 'b-', linewidth = 2, label = 'Exact')       \n",
    "    ax.plot(x,u_pred.T[750,:], 'r', linewidth = 2, label = 'Prediction')\n",
    "    ax.set_xlabel('$x$')\n",
    "    ax.set_ylabel('$u(x,t)$')\n",
    "    #ax.axis('square')\n",
    "    ax.set_xlim([-1.1,1.1])\n",
    "    ax.set_ylim([-0.1,9])    \n",
    "    ax.set_title('$t = 0.15s$', fontsize = 10)\n",
    "    \n",
    "    #plt.tight_layout()\n",
    "    plt.savefig('Ornstein-Uhlenbeck.png',dpi = 500)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YRuuEXx-eeWa"
   },
   "source": [
    "# *Model Training and Testing*\n",
    "\n",
    "A function '**model**' is defined to generate a NN as per the input set of hyperparameters, which is then trained and tested. The L2 Norm of the solution error is returned as a comparison metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WyH2oLRH3j9K",
    "outputId": "2a6e482f-0246-4bcc-f61a-b2eda8c48a7b",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.25038482113603844 0.11639639443683664 0.1339884266992018 3.6237329634650064\n",
      "1 0.22758593244639505 0.10865924123095311 0.11892669121544194 3.185946662441817\n",
      "2 0.128284115117695 0.09601519744083592 0.032268917676859077 1.1421535868603157\n",
      "3 0.10687128282207908 0.093823269720958641 0.013048013101120443 1.0699352669391688\n",
      "4 0.095982269620095789 0.0915792468406159 0.0044030227794798951 1.3049766317800755\n",
      "5 0.09503006181290162 0.09201373253819814 0.0030163292747034868 1.3784346777941592\n",
      "6 0.094654780764170734 0.0918888281168219 0.0027659526473488307 1.3562704852564351\n",
      "7 0.094569177906560262 0.091879163923578214 0.002690013982982051 1.3343442523816313\n",
      "8 0.09439705370305905 0.091881401046200392 0.002515652656858654 1.2967138768408675\n",
      "9 0.093957714587361282 0.09187209369722811 0.0020856208901331684 1.2501011310785866\n",
      "10 0.09299694969673461 0.091740942671077477 0.0012560070256571385 1.2310329442628054\n",
      "11 0.091873864362852109 0.091338560825792323 0.00053530353705978314 1.3175761180284271\n",
      "12 0.091296996615951753 0.090909292218979379 0.00038770439697237722 1.4242146900225934\n",
      "13 0.091149006405991842 0.09078048564441768 0.000368520761574161 1.413925983038439\n",
      "14 0.091020107826914332 0.090596921523539722 0.00042318630337461382 1.4135860681809531\n",
      "15 0.0909536462471797 0.0905193972966468 0.00043424895053290616 1.4276164272473248\n",
      "16 0.090636185712265463 0.090183992092664908 0.00045219361960054891 1.4746708555154089\n",
      "17 0.090190528567842085 0.08976283749135347 0.000427691076488612 1.5081982757901298\n",
      "18 0.0895725924294511 0.089135222958590721 0.00043736947086038172 1.6565663807565754\n",
      "19 0.0891659652660848 0.088617424197582159 0.00054854106850264707 1.6310078906235923\n",
      "20 0.08892561888267457 0.088216629150272077 0.00070898973240249308 1.6073625549808794\n",
      "21 0.088806723109903118 0.08792008113403553 0.00088664197586758669 1.493696966877878\n",
      "22 0.088633004214777447 0.087564247579156318 0.001068756635621124 1.5591576382397234\n",
      "23 0.088541205622970479 0.087440560134838474 0.0011006454881320106 1.567932411463726\n",
      "24 0.088442390160738085 0.087242101845836251 0.0012002883149018328 1.5778881630484267\n",
      "25 0.088255393696479625 0.0869105333169137 0.0013448603795659197 1.6227904201079528\n",
      "26 0.087990728199326532 0.08640406732627795 0.0015866608730485865 1.643131015796644\n",
      "27 0.08781866784145817 0.086155959077663408 0.0016627087637947624 1.6409977511122538\n",
      "28 0.087626678859203569 0.085988597289295227 0.0016380815699083451 1.6519873674702286\n",
      "29 0.087359545144238965 0.085589544062536313 0.0017700010817026518 1.683001806945794\n",
      "30 0.0869890885623875 0.085056651046271067 0.0019324375161164393 1.7597110356378376\n",
      "31 0.08638446568181557 0.084278575743469877 0.00210588993834569 1.7616276561427053\n",
      "32 0.086239867773347939 0.084181469536414533 0.0020583982369334073 1.841192796692692\n",
      "33 0.086189247041056807 0.084139213785948408 0.0020500332551084055 1.9823626907986112\n",
      "34 0.085935867650751521 0.084042963239183324 0.0018929044115681957 1.9302649017048579\n",
      "35 0.085544054755797377 0.0838194292840979 0.0017246254716994775 1.8886706634557109\n",
      "36 0.0850730948957648 0.083622412775983049 0.001450682119781749 1.8590895613447573\n",
      "37 0.084708920132213983 0.083462224888612643 0.0012466952436013417 1.8743415255124058\n",
      "38 0.0844645471224004 0.083123197673670893 0.0013413494487294973 2.0499783305502497\n",
      "39 0.084293846854102211 0.083005700905160726 0.001288145948941481 2.0810125139786586\n",
      "40 0.084058397673354615 0.0827503345807226 0.0013080630926320131 2.1240716731034466\n",
      "41 0.083800522991719709 0.082351621162676455 0.0014489018290432536 2.2243747732002546\n",
      "42 0.083579365611197234 0.082244778973208546 0.0013345866379886825 2.1343275725728645\n",
      "43 0.08335681068879465 0.082184509801335251 0.0011723008874593985 2.0993137188544067\n",
      "44 0.082712268336112477 0.081874723209120676 0.000837545126991796 2.0368393434500667\n",
      "45 0.082337495242356812 0.081517758531855472 0.00081973671050133967 2.0681747365153393\n",
      "46 0.081803475774855486 0.080775796072469347 0.0010276797023861357 2.1899702115268402\n",
      "47 0.080894997586632669 0.07947074561143061 0.0014242519752020607 2.449952448571315\n",
      "48 0.080473082938980908 0.078767790332547036 0.0017052926064338694 2.531379313457261\n",
      "49 0.080326508337395339 0.078650199651588149 0.0016763086858071928 2.5119040340819323\n",
      "Training time: 87.02\n",
      "      fun: 0.08032650833739534\n",
      " hess_inv: <3041x3041 LbfgsInvHessProduct with dtype=float64>\n",
      "      jac: array([ 1.46368163e-04, -9.04920046e-05,  8.39873036e-04, ...,\n",
      "        4.25794624e-03, -1.09667721e-03, -8.08746264e-03])\n",
      "  message: 'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
      "     nfev: 55\n",
      "      nit: 50\n",
      "     njev: 55\n",
      "   status: 1\n",
      "  success: False\n",
      "        x: array([ 0.2145415 ,  0.20490637,  0.03217297, ..., -0.22611066,\n",
      "        0.04540183, -0.17630123])\n",
      "Test Error: 2.51190\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Solution Plot '"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_u = 60000 #Total number of data points for 'u'\n",
    "N_f = 10000 #Total number of collocation points \n",
    "\n",
    "# Training data\n",
    "X_f_train, X_u_train, u_train = trainingdata(N_u, N_f)\n",
    "\n",
    "layers = np.array([3,20,20,20,20,20,20,20,20,1]) #8 hidden layers\n",
    "\n",
    "PINN = Sequentialmodel(layers)\n",
    "\n",
    "init_params = PINN.get_weights().numpy()\n",
    "\n",
    "start_time = time.time() \n",
    "\n",
    "# train the model with Scipy L-BFGS optimizer\n",
    "results = scipy.optimize.minimize(fun = PINN.optimizerfunc, \n",
    "                                  x0 = init_params, \n",
    "                                  args=(), \n",
    "                                  method='L-BFGS-B', \n",
    "                                  jac= True,        # If jac is True, fun is assumed to return the gradient along with the objective function\n",
    "                                  callback = PINN.optimizer_callback, \n",
    "                                  options = {'disp': None,\n",
    "                                            'maxcor': 200, \n",
    "                                            'ftol': 1 * np.finfo(float).eps,  #The iteration stops when (f^k - f^{k+1})/max{|f^k|,|f^{k+1}|,1} <= ftol\n",
    "                                            'gtol': 5e-8, \n",
    "                                            'maxfun':  50000, \n",
    "                                            'maxiter': 50,\n",
    "                                            'iprint': -1,   #print update every 50 iterations\n",
    "                                            'maxls': 50})\n",
    "\n",
    "elapsed = time.time() - start_time                \n",
    "print('Training time: %.2f' % (elapsed))\n",
    "\n",
    "print(results)\n",
    "\n",
    "PINN.set_weights(results.x)\n",
    "\n",
    "''' Model Accuracy ''' \n",
    "u_pred = PINN.evaluate(X_u_test)\n",
    "\n",
    "error_vec = np.linalg.norm((u-u_pred),2)/np.linalg.norm(u,2)        # Relative L2 Norm of the error (Vector)\n",
    "print('Test Error: %.5f'  % (error_vec))\n",
    "\n",
    "#u_pred = np.reshape(u_pred,(256,1000),order='F')                        # Fortran Style ,stacked column wise!\n",
    "\n",
    "''' Solution Plot '''\n",
    "#solutionplot(u_pred,X_u_train,u_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "u_pred = np.reshape(u_pred,(128, 128, 100), order='F')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_3d_ic(time):\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    ax = plt.axes(projection='3d')\n",
    "    ax.plot_surface(X[:,:,0], Y[:,:,0], usol[:,:,time])\n",
    "    ax.set_zlim(0, 2)\n",
    "def plot_3d_pred(time):\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    ax = plt.axes(projection='3d')\n",
    "    ax.plot_surface(X[:,:,0], Y[:,:,0], u_pred[:,:,time])\n",
    "    ax.set_zlim(0, 2)\n",
    "    \n",
    "    \n",
    "def plot_2d(time):\n",
    "    plt.plot(y, u_pred[:,64,time])\n",
    "    plt.plot(y, u_pred[64,:,time])\n",
    "    #plt.ylim(0, 2)\n",
    "    #plt.xlim(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e01b7410de3f4d1c96aada0fa3a17fd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=48, description='time', max=99, step=2), Output()), _dom_classes=('widge…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e43123cff47a408e939a55360a25dbb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=48, description='time', max=99, step=2), Output()), _dom_classes=('widge…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b408d95369a4c958c115455e41fbabb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=48, description='time', max=99, step=2), Output()), _dom_classes=('widge…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_3d_pred(time)>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ipywidgets\n",
    "\n",
    "ipywidgets.interact(plot_2d, time=(0, 99, 2))        \n",
    "ipywidgets.interact(plot_3d_ic, time=(0, 99, 2))\n",
    "ipywidgets.interact(plot_3d_pred, time=(0, 99, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "OrnsteinUhlenbeck_lateral_ic.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
